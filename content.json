{"posts":[{"title":"重新开始","text":"重新开始 重新开始第一篇，坚持！：）","link":"/2020/07/09/2020-07-09-21/"},{"title":"使用marp和pandoc写作slide","text":"使用marp写作slide 在vscode 中安装marp 插件即可在在vscode中使用markdown书写slide，写作PPT过程可以专注有书写内容，如果PPT对排版要求比较简单可以按照marp对语法（markdown对语法扩展）直接进行简单排版。Marp支持简单对水平排版，和自定义语法图文排版，如果材料以图和关键字为主则Marp可以较好支持书写和排版。如果文件较多、排版较为复杂则需要将输出结果导出到PPT中使用PPT模板和排版工具快速完成排版。 使用Marp写作Slide Marp语法请参考：https://marpit.marp.app/markdown 导出成PPT 写作完成slide之后，如果对排版要求比较简单可以将markdown导出成PDF或HTML文档；Marp也支持直接导出成PPT文件，由于Marp导出对PPT文件是将文件生成为图片再将图片打包成PPT文件，该PPT文件是无法编辑内容，如果需要在PPT中重新排版就需要借助pandoc工具。 - 安装pandoc工具 - windows在https://www.pandoc.org/ 下载安装文件完成安装； - linux 使用软件仓库可直接安装pandoc - 配置potx模板 在https://templates.office.com/中选择喜欢的模板，将模板保存到本地工作目录备用。建议在PPT中视图-〉幻灯片母板中调整模板，将文本框调整成自动缩放文字。 - 使用pandoc将markdown文件转成pptx文件 1pandoc -f markdown -t pptx --reference-doc=template.potx -o output.pptx input.md ### 使用PPT调整排版 使用布局（layout）功能快速调整排版","link":"/2020/07/10/2020-07-10-22/"},{"title":"公有云厂家的混合云产品","text":"2017年以前公有云厂家和私有厂家是半推半就的竞争关系。每家云厂商根据自己的业务强项推出了不同对混合云产品，业界对混合云对定位也不统一。 AWS AWS认知的混合云是基础设施对混合云，逐步到服务级对混合云部署； Azure Azure认知的混合云是Azure Stack + Azure对组合，混合云是Azure在客户机房对延伸； Google Google认知对混合云就是基于容器的Anthos，通过容器实现基础设施级应用部署混合云； VMware 放弃公有云市场，发挥自身SDDC优势，拥抱公有云厂商的基础设施，和公有云厂商形成了优势互补，另一方面积极补齐私有云侧容器能力； 2019年Google收购CloudSimple并于2020年5月推出基于CloudSimple的Google VMware Engine，Azure也和VMware达成和解于2020年5月推出了由Azure自研的Azure VMware Solution；公有云厂商对混合云战略逐步清晰。 AWS 基础设施的+服务混合部署：加速outposts对进度，逐步将高级服务能力下移到outposts；继续和VMware合作，推出基于EBS对裸金属实例； Azure 和VMware和解、IaaS基础设施由vMware解决方法完成，Azure Stack无重大更新；聚焦PaaS，通过Azure Arc 和App 服务组合打造应用混合部署能力； Google 推出 Google VMware Engine补齐IaaS混合云能力；和Anthos组合成IaaS+PaaS完整对混合云解决方案。","link":"/2020/07/12/2020-07-12-08/"},{"title":"解决hexo无法使用本地图片问题","text":"转载自:http://www.manongjc.com/detail/9-bayyqoeqtjoljpu.html 版本：Hexo 3以上 最近搭建hexo博客时遇到了图片部署后不显示的问题，如图： 示例图片 上网找了很多方式都没有完美解决问题，后来查看了官方文档后终于解决了问题（完美解决），现在贴出来如下。建议以后大家遇到了问题也先去看看官方文档：https://hexo.io/zh-cn/docs 解决方案如下： 在根目录下配置文件_config.yml 中有 post_asset_folder:false改为true。这样在建立文件时，Hexo会自动建立一个与文章同名的文件夹，这样就可以把与该文章相关的所有资源（图片）都放到那个文件夹里方便后面引用。如这里我放了一张test.jpg的图片。 git bash安装插件： 1npm install https://github.com/7ym0n/hexo-asset-image --save 使用这个插件来引入图片（这是个修改过的插件，经测试无问题），而不是网上那些方法里说的用传统md语法相对路径的方法。 插入图片时用这种方式： 1{% asset_img test.jpg This is an test image %} 其中test.jpg就是你要引用的图片，我这里就是test.jpg，后面的This is an test image是图片描述，可以自己修改。 这样就能成功显示了，测试下吧：hexo cl &amp;&amp; hexo g &amp;&amp; hexo d 2020-8-13日更新 1232. git bash安装插件： ``` shell npm install https://github.com/7ym0n/hexo-asset-image --save 使用这个插件来引入图片（这是个修改过的插件，经测试无问题），而不是网上那些方法里说的用传统md语法相对路径的方法。 ``` 将上面命令替换成: npm install hexo-simple-image --save 在markdown文件中使用 ![](./dir/image.png) 在图片路径钱必须加上\"./\"，否则hexo g生成文件时会报错。","link":"/2020/07/12/2020-07-12-22/"},{"title":"非暴力沟通读书笔记（一）","text":"非暴力沟通中强调合理表达诉求，而不是指责、批评或者抱怨对方对行为。例如： 案例一 &gt; 我很生气，你惹我不高兴了! 更好一些对表达是： &gt; 你约会迟到了，我很生气。 但是上述表达中表达了自己对感受，但是指责了对方的行为，需要将指责对方的行为修改为表达自己对诉求： &gt; 我很生气，我希望你约会能按时到，这样我们就有时间一起吃饭，还可以看一场电影。 案例二 &gt; 如果你下次在这样做事情，你不如不做！ 需要将上述对沟通方式调整为表达自己对感受，并说出自己对需求/诉求： 我很失望，我希望你在涮碗的同时也把餐桌擦干净，这样我就不需要做这些了。 我们的愤怒、不高兴、失望等负面情绪往往是因为我们的期望没有得到满足，在沟通过程中如果只是通过批评、吼叫等行为表达了自己的情绪，而不是通过非暴力对方式表达自己对诉求/需求。在听到不中听对话我们往往会产生以下行为： 1. 认为自己犯了错，而产生自责或这内疚的情绪 2. 指责对方，或者驳斥对方 3. 了解我们对感受和需要 4. 用心体会他人对感受和需要 因此在沟通过程中表达自身对感受和需要，倾听对方对感受和需要开始非暴力对沟通。","link":"/2020/07/13/2020-07-13-22/"},{"title":"非暴力沟通读书笔记（二）","text":"非暴力沟通过程中除了报答自己的感受、需要和请求外也许要关注对方，也许要想对自己一样观察、感受对方，了解对方的需求和请求。 体会他人对感受和需求 在体会他人的感受和需要是不要基于发表自己对看法、判断和建议等。 给他人反馈 在倾听到他人对感受、需求和请求等需要给予他人反馈，主动表达我们的理解。如果我们理解正确可以帮助对方意识到他们他们要表达对意思；如果我们理解不到位，对方则可以继续补充。 一般来说一个人讲话时如果带有明显对情绪时他一般会期待得到反馈。即使在不善于表达情感的人之间只要用心体会他人对感受都会促进两者之间关系，例如：中年儿子和年迈对父亲之间。 保持关注 我们需要在为他人表达创造条件，确保我们已经充分对观察、感受对方对需求和请求时再给予他人的建议，如果过早给对方建议，没有让对方体会到我们已经真正理解和体会到对方对感受了，对方往往会认为我们建议是敷衍的，或者是否能真正发挥作用。 如果当我们痛苦的无法倾听，这说明我们也许要别人的关心，请大声说出你对感受、需要和请求。 非暴力沟通不是一个沟通对技巧，是发自内心的爱或者真诚的希望改善和周围人关系。","link":"/2020/07/17/2020-07-17-20/"},{"title":"使用PAC文件实现浏览器自动代理","text":"由于工作原因需要经常在不同的地方（办公室、家庭网络、机场酒店公共网络）接入到办公网络，而办公网络需要通过公司代理服务器才能访问互联网，同时公司IT部门提供了国内、海外等不同的代理服务器，这样就需要根据是否接入办公网络及访问对网址经常修改代理服务器（打开、关闭、修改不同对代理服务器等）。 目前各主流浏览器均支持Proxy Auto-Configuration (PAC) file自动设置代理，详细对配置指导可参考https://developer.mozilla.org/en-US/docs/Web/HTTP/Proxy_servers_and_tunneling/Proxy_Auto-Configuration_(PAC)_file。 今天主要讨论根据接入网络和访问的目标网址设置不同的代理服务器策略。 需求一：根据是否接入办公网络选择不同的Proxy策略 通过家庭、酒店WIFI未（通过VPN）接入公司网络，本机localhost地址通常是192.168.x.x； 通过家庭、酒店WIFI（通过VPN）接入公司网络时，本机localhost地址通常是127.0.0.1； 通过办公室WIFI接入公司网络和场景2类似； 需求二：根据目标网址选咋不同的Proxy服务器； 如果访问公司内网则不想要代理服务器； 如果是访问海外网络则选择海外Proxy服务器； 其他情况均使用国内代理服务器。 通过PAC自动选择代理服务器 12345678910111213141516171819202122function FindProxyForURL(url, host) { //如果没有通过VPN接入公司网络 if (isInNet(dnsResolve('localhost'),'192.168.0.0','255.255.0.0') || dnsResolve('localhost') != '127.0.0.1' // 不同对公司网络可能有差异，可以使用nslookup localhost 查询 ) { return 'DIRECT'; } //如果访问的时公司内网 if (shExpMatch(host, &quot;*.mycompany.com&quot;)) { return 'DIRECT'; } // 如果访问对的时海外网址使用海外Proxy if (shExpMatch(url,'*.google.com*') || shExpMatch(url,'*.github.com*') ) { return 'PROXY proxy_uk.mycompany.com:8080' + 'PROXY proxy_hk.mycompany.com:8080'; }else { //默认使用国内proxy，如果proxy不同则不使用 return 'PROXY proxy_cn.mycompany.com:8080;' + 'DIRECT' }} 在浏览器设置PAC文件 各家浏览器均可以使用扩展或者命令参数设置PAC文件。这里推荐使用Proxy-Switcher扩展，该扩展支持Chrome/Edge/Firefox浏览器，具体参考：https://mybrowseraddon.com/proxy-switcher.html","link":"/2020/07/19/2020-07-19-00/"},{"title":"MX Linux 安装及配置","text":"前几天看头条上推荐MX Linux，MX Linux号称是DistroWatch排名第一的操作系统，大部分评论时易用性比较好，此时手上恰好有一块闲置的高速U盘，就是想将MX Linux安装到U盘上尝试使用一下。 准备工作 杂牌4G U盘：用于制作USB启动盘 ScanDisk 64G USB 3.0 高速U盘：安装MX Linux到此盘； 从清华镜像站https://mirrors.tuna.tsinghua.edu.cn/下载最新对MX Linux IOS文件 制作启动盘 使用fdisk命令清除了4G U盘的信息，再格式化成fat32（不格式化无法自动挂载，尝试着手工挂载unbootin工具均无法识别出U盘，于是放弃了使用unbootin工具制作启动U盘）； 使用dd命令制作启动U盘，dd命令使用方法自行请百度 sudo dd if=/home/mxipp/Downloads/MX-19.2_x64.iso of=/dev/sdd &gt; 由4G U盘是USB 2.0接口的杂牌U盘，写入速度极慢，大约用10分钟才制作好启动U盘 安装MX Linux 安装MX Linux前设置PC的启动选项为U盘启动 如果PC只有一个USB 3.0接口，其他USB接口为USB 2.0接口，建议将USB启动盘插到USB 2.0接口（暂时不要插入64G U盘），重启PC当PC使用U盘启动盘启动时再插入64GU盘； 系统启动后按照Live USB 系统的安装指引完成系统开始安装 需要注意的是在设置安装盘时务必选择安装到64G U盘，如果错配成PC硬盘安装时会清除硬盘上的数据； 引导程序也要选择安装到64G U盘上 &gt; 如果不清楚64G U盘挂载信息可用 sudo fdisk -l 命令查询，或者简单用盘大小判断。 整个安装过程都是图形化操作，其他安装设置这里就不赘述了。安装完成之后系统会要求重启，重启时请拔掉4G启动盘，系统启动时就会使用安装到U盘的MX Linux启动。 设置MX Linux MX Linux是基于Debian 10稳定版的发行版本，相关Debian文档进行设置，本文只说明几个关键设置。 设置国内源 不建议使用MX Linux图形化的repo manager修改源，repo manager修改非security源，security 源还是使用debian，更新、安装还是很慢。 建议按照清华镜像站的帮助https://mirrors.tuna.tsinghua.edu.cn/help/debian/直接修改/etc/apt/sources.list 更新系统 sudo apt update &amp; upgrade 安装中文输入法 推荐使用rime中文输入法:http://www.rime.im。刚开始安装时直接按照rime官网指导使用如下命令安装rime输入法： sudo apt intall ibus-rime 安装成功后遇到2个折腾了很久的问题： rime部署时报错： rime提示部署失败，错误日志记录在/tmp/目录下，实际该目录下找不到错误文件，重试多次均无法使用 Ibus不能随系统启动 首先按照系统提示在.bashrc中添加环境变量，实际并不能生效； 123export XMODIFIERS=@im=ibusexport GTK_IM_MODULE=ibus export QT_IM_MODULE=ibus 于是又在百度查到有些人建议在/etc/environment或者/etc/profile中配置均无法正常工作，折腾了2个小时也无法解决问题，于是就想到在linxu系统自动启动程序中增加ibus-daemon -dx命令，保存了一下session貌似可以正常启动ibus了，但是rime仍然无法正确工作，还是放弃了此方法。最终通过bing搜索引擎在MX Linux的官网上查到配置中文输入法的wikihttps://mxlinux.org/wiki/other/chinese-simplified-input/，同时在archwiki查询ibus相关指导https://wiki.archlinux.org/index.php/IBus，最终按照指导配置，ibus 和rime均能够正常工作。 具体设置如下： 在.xprofile和.bashrc中配置 1234export XMODIFIERS=@im=ibusexport GTK_IM_MODULE=ibus export QT_IM_MODULE=ibusibus-daemon -drx 通过MX Package Installer安装chinese-ibus，系统在安装过程中会同步安装关联的im-config工具，执行im-config -n ibus 重启PC，ibus和rime均能够正常工作 实际在输入的安装过程中，mxlinux wiki和archwiki配置如何时ibus和rime正常工作暂未深入研究，后续有机会补充Display Manager和profile文件bashrc文件之间关系后续再详细说明 几点折腾感悟 技术试用、学习过程中遇到阻塞性问题，尽量在官方英文文档中查找解决问题的方法； 国内百度搜索出来的东西实在不敢恭维了，使用百度搜索即使用多个英文关键字也无法搜索出强管理的英文官方网址，使用bing搜索前5条即可找到官方后者权威技术材料； Arch linux指导文档详细且全面，知识点之间的关联性非常好，而且文档指导性很强； MX Linux并不适合初学者用，遇到问题常常的方案很难解决； Debian稳定性比较好，在10年ThinkPad T400 + 64G U盘上运行的很流畅，没有出现在Manjaro、LinuxMint上出现卡死问题（基本上是由于浏览器、编辑器等软件要求硬件加速导致的）","link":"/2020/07/23/2020-07-23-22/"},{"title":"在Windwos 10 WSL2中安装Docker","text":"最近在学习kubernets，正在阅读《Kubernetes in action》一书，为了感性化的理解书中内容决定同步在办公PC上安装书中涉及到工具和代码，今天先完成在win 10 WSL2中安装Docker。首先在win 10 WSL2中安装Docker想法是基于微软宣称的WSL2内核是真正的Linux内核，也就想当然的认为WSL2中的Ubuntu 20.04和在PC上直接安装是一致的，结果在安装过程中遇到各种小插曲。 打开硬件虚拟化支持 在BIOS中设置Intel虚拟化支持，进入到Virtualization选项中，设置Intel Virtual Technology为enable。重启以后即可在windows任务管理器-〉性能面板中查询虚拟化已开启。 升级WSL-〉WSL2 升级win10到支持WLS2版本，Version 2004, Build 19041 or higher; 设置WSL版本 在cmd中输入如下命令：wsl --set-default-version 2，将wsl版本设置为WSL2。 安全ubuntu 20.04 在windows store中搜索ubuntu 20.04，安装ubuntu 20.04版本；安装完成后启动ubuntu 20.04系统提示 详细配置参考：https://docs.microsoft.com/en-us/windows/wsl/ 安装Docker 安装windows 10版本的Docker 不要直接使用系统apt的命令安装docker.io；建议下载windows 10的Docker版本，设置启动WSL即可。 检查Docker安装是否成功 使用：sudo docker version查询docker版本： ### 如果显示如下信息则说明server端没有启动或者连接失败： 12345678910Client:Version: 19.03.12-ceAPI version: 1.40Go version: go1.14.4Git commit: 48a66213feBuilt: Wed Jul 1 17:05:50 2020OS/Arch: linux/amd64Experimental: falseGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get &quot;http://%2Fvar%2Frun%2Fdocker.sock/v1.40/version&quot;: dial unix /var/run/docker.sock: connect: permission denied 解决方案： 使用sudo docker version查询，如果仍然显示失败； 检查server是否启动 如果显示如下信息则说明启动成功： 12345678910111213141516171819202122232425262728Client:Version: 19.03.12-ceAPI version: 1.40Go version: go1.14.4Git commit: 48a66213feBuilt: Wed Jul 1 17:05:50 2020OS/Arch: linux/amd64Experimental: falseServer:Engine:Version: 19.03.12-ceAPI version: 1.40 (minimum version 1.12)Go version: go1.14.4Git commit: 48a66213feBuilt: Wed Jul 1 17:05:26 2020OS/Arch: linux/amd64Experimental: falsecontainerd:Version: v1.3.4.mGitCommit: d76c121f76a5fc8a462dc64594aea72fe18e1178.mrunc:Version: 1.0.0-rc91GitCommit: 24a3cf88a7ae5f4995f6750654c0e2ca61ef4bb2docker-init:Version: 0.18.0GitCommit: fec3683 ## 配置Docker 配置国内源 在Windows中配置国内源 配置Dokcer国内源时需要打开（图形化的）Docker Desktop，直接设置国内源即可；如果 在Linux系统中配置源，直接修改/etc/docker/daemon.json文件即可。详细请参考:https://docs.docker.com/registry/recipes/mirror/ 配置文件格式为JSON格式，例如： 123{ &quot;registry-mirrors&quot;: [&quot;https://&lt;my-docker-mirror-host&gt;&quot;]} 常用的国内Docker如下： - docker官方中国区: https://registry.docker-cn.com - 网易: http://hub-mirror.c.163.com - ustc: http://docker.mirrors.ustc.edu.cn 可以同时配置多个源，例如： 123456{ &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot;, &quot;http://hub-mirror.c.163.com&quot; ]} 重启Docker服务即可生效 在Linux执行如下命令： 12sudo systemctl daemon-reloadsudo systemctl restart docker 如果重启提示错误可以可根据提示的命令定位错误原因。 &gt; Job for docker.service failed because the control process exited with error code. &gt; &gt; See \"systemctl status docker.service\" and \"journalctl -xe\" for details. 查询配置是否生效 sudo docker info","link":"/2020/07/26/2020-07-26-20/"},{"title":"完成第一个docker应用程序","text":"本文参考《Kubernetes in action》中的案例，部署一个node.js应用。在vscode中搭建node.js开发环境请自行百度。 创建应用程序 12345678var http=require('http');http.createServer(function(req,res){ res.writeHead(200,{'Content-Type':'text/plain'}); res.end('hello node.js'); }).listen(3000,'0.0.0.0',function(){ console.log('Server running at http://localhost:3000');}); 使用 node app.js启动应用程序，使用curl localhost:3000即可验证应用部署是否成功。 编写Dockerfile 123FROM node:12ADD app.js /app.js ENTRYPOINT [ &quot;node&quot;, &quot;app.js&quot; ] &gt; 注意： &gt; 1. dockerfile 和app.js 在同一目录下 &gt; 2. node版本号最好根据当期开发环境中版本保存一致，具体版本号使用node -v查询 制作镜像 在dockerfile目录下执行命令：sudo docker build -t kubia . 运行程序 sudo docker run --name kubia-container -p 3000:3000 -d kubia 验证应用 在浏览器中访问http://docker-ip:3000，浏览器显示hello node.js。docker ip可以通过ifconfig/ipconfig 命令查询","link":"/2020/07/28/2020-07-28-23/"},{"title":"使用minikube部署本地镜像","text":"启用本地镜像Hub 使用如下命令启动本地镜像仓库 sudo docker run -d -p 5000:5000 --restart=always --name registry registry 查询是否启用成功 curl -X GET 172.17.0.1:5000/v2/_catalog 因为当前没有Push任何镜像到本地镜像仓库，查询结果是空。 Push镜像到local Hub 为本地镜像打一个tag docker tag kubia 172.17.0.1:5000/kubia 向本地镜像仓库推送镜像 docker push 172.17.0.1:5000/kubia 再次查询本地镜像仓库 curl -X GET 172.17.0.1:5000/v2/_catalog 返回: {\"repositories\":[\"kubia\"]} 添加本地镜像到配置文件 sudo vim /etc/docker/daemon.json 加入如下信息： 12345678{ &quot;registry-mirrors&quot;: [ &quot;https://hub-mirror.c.163.com&quot;, &quot;https://registry.docker-cn.com&quot; ], &quot;insecure-registries&quot;:[&quot;172.17.0.1:5000&quot;] //增加本地镜像地址} 这里的配置需要注意：172.17.0.1:5000，需要和tag镜像信息保持一致; 重启docker服务是配置生效： systemctl restart docker 新建一个minikube集群 minikube start --driver=docker --insecure-registry=\"172.17.0.1:5000\" --registry-mirror=\"https://hub-mirror.c.163.com\" 这里的本地ip地址必须和上述配置的一致。 由于docker pull镜像默认使用的https协议，因此需要明确告诉docker服务和minikube使用http协议（insecure-registry） 从local registry运行一个docker应用 运行docker应用 kubectl run kubia --image=172.17.0.1:5000/kubia --port 3000 系统会返回：pod/kubia created docker run是运行一个rs，而不是delploy一个应用，无需要指定部署文件 查询POD信息 kubectl get pods，系统会返回pod运行状态，如果有异常可以使用 kubectl describe pod kubia 查询详细信息。 12NAME READY STATUS RESTARTS AGEkubia 1/1 Running 0 16s 创建服务对象 此时虽然已经集群内部部署成功，应用仍然无法从集群外部访问，此时需要通过服务开放接口 sudo kubectl expose pod kubia --name kubia-http --type=LoadBalancer 由于minikube不支持LoaderBalancer类型，使用默认的type类型也可以。 列出服务 kubectl get services 系统返回服务信息： 123NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEKubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 13mkubia-http LoadBalancer 10.99.35.111 &lt;pending&gt; 3000:31902/TCP 97s 此时查询到服务仍然未分配外部IP，minikube可以使用 minikube service kubia-http访问的服务的IP和端口。 123456|-----------|------------|-------------|---------------------------|| NAMESPACE | NAME | TARGET PORT | URL ||-----------|------------|-------------|---------------------------|| default | kubia-http | 3000 | http://192.168.3.15:31902 ||-----------|------------|-------------|---------------------------| 使用http://192.168.3.15:31902即可访问服务。 pod，service和rc之间的关系 镜像推送部署和应用部署流程","link":"/2020/08/12/2020-08-12-23/"},{"title":"Kubernetes发现服务","text":"Kubernetes发现服务 由于Kubernetes的POD的生命是短暂的，可以随时被创建和销毁，不能通过指定IP和端口号被客户端发现。另外，对于水平伸缩的POD，由多个POD提供服务，客户端也无需关心由那个POD提供服务，也就无需关心POD的部署位置。 通过引入服务（Service）提供稳定外部访问机制。 我们可以为服务创建多个端口。例如：一个servcie可以有80和443端口，通过80和443端口将外部访问转发到POD的8080和8443端口。 服务发现 通过环境变量发现服务 服务的创建早于POD，POD创建时k8s会通过环境变量发现服务； 通过DNS发现服务 k8s集群提供了一个kube-dns POD，所有的POD都使用DNS（通过修改POD的/etc/resolv.conf文件实现）。 通过FQPN发现服务","link":"/2020/09/02/2020-09-02-20/"},{"title":"Kubernetes将服务暴露给外部方式","text":"kubernets集群内部的服务可以直接环境变量、内部DNS等方式被发现，并在集群内部提供服务。如何将Kubernetes的服务暴露给外部客户端呢？ Kubernetes提供以下集中方式将服务暴露给开外部客户端： 通过NodePort暴露服务 顾名思义，将服务类型设置成NodePort方式，Kubernetes会在集群每个节点上打开一个端口，将该端口的流量转发到服务的POD。 通过负载均衡器暴露 负载均衡方式实际是NodePort方式的增强，将服务类型设置成LoadBalancer方式实际是通过云基础架构提供的负载均衡器，将流量转发到集群内部的NodePort上。 通过Ingress暴露 Ingress是Kubernetes一种资源，通过类似LoadBalancer类似的能力，区别在于每个LoadBalancer都需要一个独立的公网IP，而Ingress只需要一个公网IP即可根据规则将流量转发到对应的服务。","link":"/2020/09/16/2020-09-16-22/"},{"title":"Kubernetes挂载存储","text":"示例说明 为演示在Kubernetes挂载存储以下面为例： fortune进程 利用fortune游戏每10秒钟更新一次html文档；并将更新过程钟写入日志。 web-server进程 使用nginx作为web服务器向外提供服务，客户展示fortune生成的html文件。 log-server进程 使用nginx作为服务器向外提供服务，可以查询fortune日志。 分别将上述进程部署到不同的容器中，容器间通过挂载emptyDir卷共享信息。 测试代码 fortune程序 123456789101112#! /bin/bashtrap &quot;exit&quot; SIGINTmkdir /var/htdocsmkdir /var/fortunewhile : do echo $(date) writing fortune to /var/htdocs/index.html &gt;&gt; /var/log/fortune/$(date +%Y-%m-%d).log /usr/games/fortune &gt; /var/htdocs/index.html sleep 10done 每10秒钟生成一次html文件，并记录生成日志 fortune的dockerfile 12345FROM ubuntu:latestRUN apt update ; apt install -y fortuneADD fortuneloop.sh /bin/fortuneloop.shENTRYPOINT /bin/fortuneloop.sh 将三个示例容器部署到一个POD中 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: v1kind: Podmetadata: name: fortune labels: app: fortunespec: containers: - name: html-gen image: 172.17.0.1:5000/fortune volumeMounts: - name: html mountPath: /var/htdocs - name: log mountPath: /var/log/fortune - name: web-server image: 172.17.0.1:500/nginx:alpine volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 protocol: TCP - name: log-server image: 172.17.0.1:5000/nginx:log volumeMounts: - name: log mountPath: /usr/share/nginx/log readOnly: true ports: - containerPort: 8080 protocol: TCP volumes: - name: html emptyDir: {} - name: log emptyDir: {} nginx:log源于nginx:alpine镜像，只是将nginx默认80端口修改成8080端口，将默认的html root目录修改成/usr/share/nginx/log目录，具体修改方法下次在详细讲。 建立一个NodePort类型的Service对外提供web服务 12345678910111213kind: ServiceapiVersion: v1metadata: name: fortune-web-nodeportspec: selector: app: fortune type: NodePort ports: - port: 8088 targetPort: 80 nodePort: 30157 注意selector实际是按照POD中容器标签进行选择的，因此该信息必须和POD中设置的标签保持一致； targetPort和容器端口一致，nginx:alpine默认端口是80端口 建立一个NodePort类型的Service对外提供log服务 123456789101112kind: ServiceapiVersion: v1metadata: name: fortune-log-nodeportspec: selector: app: fortune type: NodePort ports: - port: 8090 targetPort: 8080 nodePort: 30159 注意selector实际是按照POD中容器标签进行选择的，因此该信息必须和POD中设置的标签保持一致； targetPort和容器端口一致，nginx:log默认端口是8080端口 1234567891011121314151617181920apiVersion: extensions/v1beta1kind: Ingressmetadata: name: fortune-ingressspec: rules: - host: fortune-web.local.com http: paths: - path: / backend: serviceName: fortune-web-nodeport servicePort: 8088 - host: fortune-log.local.com http: paths: - path: / backend: serviceName: fortune-log-nodeport servicePort: 8090 通过Ingress对外提供访问策略，分别根据不同的域名选择到不同的服务中。 新版本的Kubernetes提供了新的网络策略接口，在后续文章中详细测试。 配置域名和IP地址 在minikube中创建ingress后可以通过：kubectl get ingress 查询ingress信息，该信息中包含了域名和IP地址的对应信息，在/etc/hosts中配置该信息即可在本机通过域名访问服务。 测试结果 查询资源信息 修改hosts文件 访问web和log服务","link":"/2020/09/17/2020-09-17-22/"},{"title":"修改docker hub上的官方镜像","text":"之前一直有个疑问，如果要在同一个Kubernetes的POD中部署两个系统镜像的容器，两个容器岂不是会有资源（网络端口号，文件等）冲突。在尝试在Kubernetes挂载不同的存储时就遇到同一个nginx镜像部署在同一个POD中，第二个POD始终失败的问题，查看日志也提示尝试多次终止了容器。猜测应该是在同一个POD中端口冲突导致第二个容器启动失败，于是修改官方nginx镜像的端口号成功在一个POD中启动了两个nginx容器。 具体操作如下： 从dokcer hub官方下载nginx:alpine镜像 docker pull nginx:alpine 查看镜像中的默认配置 12docker run -it --name nginx nginx:alpine /bin/shcat /etc/nginx/nginx.conf 修改官方镜像 根据官方镜像修改端口号及默认目录 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253user nginx;worker_processes auto;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events { worker_connections 1024;}http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; server { listen 8080; listen [::]:8080; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / { root /usr/share/nginx/log; # index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } }} 新的dockerfile 1234FROM nginx:alpineRUN mkdir -p /usr/share/nginx/logADD index.html /usr/share/nginx/log/index.htmlCOPY nginx.conf /etc/nginx/nginx.conf 构建新的镜像 docker build -t nginx:log . 本地测试成功以后就可以推送到自己的镜像仓库了：）。","link":"/2020/09/22/2020-09-22-23/"},{"title":"Kubernetes使用ConfigMap配置应用程序（一）","text":"传统的应用程序在部署时往往需要通过命令行参数、环境变量、配置文件等方式配置应用程序。Kubernetes应用程序可以通过ConfigMap和Secret来配置应用程序。ConfigMap和Secret的区别主要是Secret用于敏感数据配置，数据在Kubernetes中是加密存储的。 选择ConfigMap和Secret的原则比较简单： 非敏感数据则使用ConfigMap配置； 敏感数据使用Secret配置； 如果既有敏感数据又有非敏感数据则使用Secret配置。 ConfigMap和Secret使用方式类似，这里主要描述ConfigMap的使用方式。 这次还是以fortune应用程序为例，通过ConfigMap向fortune传递参数调整程序刷新的时间间隔。首先我看一下不借助ConfigMap我们如何通过命令参数和环境变量配置应用。 1.使用命令参数配置应用 修改fortune镜像，增加间隔参数 修改fortuneloop.sh，增加间隔参数 12345678910111213141516#! /bin/bashtrap &quot;exit&quot; SIGINTINTERVAL=$1mkdir /var/htdocsmkdir /var/fortuneecho Configured to generate new fortune every $INTERVAL seconds.while :do echo $(date) writing fortune to /var/htdocs/index.html &gt;&gt; /var/log/fortune/$(date +%Y-%m-%d).log /usr/games/fortune &gt; /var/htdocs/index.html sleep $INTERVALdone 修改Dockerfile增加默认参数 123456FROM ubuntu:latestRUN apt update ; apt install -y fortuneADD fortuneloop.sh /bin/fortuneloop.shENTRYPOINT [&quot;/bin/fortuneloop.sh&quot;]CMD [&quot;10&quot;] 重新制作镜像:docker build -t 172.17.0.1:5000/fortune:args .，并推送本地镜像仓库 本地运行镜像测试 12docker run --name fortune-args -it 172.17.0.1:5000/fortune:args 15Configured to generate new fortune every 15 seconds. 在POD中使用args覆盖容器参数 修改POD配置文件 123456789101112131415161718192021222324252627282930313233343536373839apiVersion: v1kind: Podmetadata: name: fortune labels: app: fortunespec: containers: - name: html-gen image: 172.17.0.1:5000/fortune:args args: [&quot;30&quot;] volumeMounts: - name: html mountPath: /var/htdocs - name: log mountPath: /var/log/fortune - name: web-server image: 172.17.0.1:500/nginx:alpine volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 protocol: TCP - name: log-server image: 172.17.0.1:5000/nginx:log volumeMounts: - name: log mountPath: /usr/share/nginx/log readOnly: true ports: - containerPort: 8080 protocol: TCP volumes: - name: html emptyDir: {} - name: log emptyDir: {} 这样重新创建POD即可看到应用参数更新成\"30\"秒。 2.使用环境变量配置应用 修改fortune镜像，增加间隔环境变量 修改fortuneloop.sh，使用INTERVAL代替默认值 1234567891011121314#! /bin/bashtrap &quot;exit&quot; SIGINTmkdir /var/htdocsmkdir /var/fortuneecho Configured to generate new fortune every $INTERVAL seconds.while :do echo $(date) writing fortune to /var/htdocs/index.html &gt;&gt; /var/log/fortune/$(date +%Y-%m-%d).log /usr/games/fortune &gt; /var/htdocs/index.html sleep $INTERVALdone 修改Dockerfile增加默认参数 12345FROM ubuntu:latestRUN apt update ; apt install -y fortuneADD fortuneloop.sh /bin/fortuneloop.shENTRYPOINT [&quot;/bin/fortuneloop.sh&quot;] 重新制作镜像:docker build -t 172.17.0.1:5000/fortune:env .，并推送本地镜像仓库 在POD中使用env覆盖容器参数 修改POD配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041apiVersion: v1kind: Podmetadata: name: fortune labels: app: fortunespec: containers: - name: html-gen image: 172.17.0.1:5000/fortune:env env: - name: INTERVAL value: &quot;45&quot; volumeMounts: - name: html mountPath: /var/htdocs - name: log mountPath: /var/log/fortune - name: web-server image: 172.17.0.1:500/nginx:alpine volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 protocol: TCP - name: log-server image: 172.17.0.1:5000/nginx:log volumeMounts: - name: log mountPath: /usr/share/nginx/log readOnly: true ports: - containerPort: 8080 protocol: TCP volumes: - name: html emptyDir: {} - name: log emptyDir: {} 这样重新创建POD即可看到应用参数更新成\"45\"秒。 上述两种方式，无论时通过args方式还是env方式都是将配置参数硬编码在POD配置文件中。实际应用部署的过程中，我们希望配置参数和POD配置能够解藕，这个就需要用到Kubernetes提供的ConfigMap来实现。","link":"/2020/09/28/2020-09-28-22/"},{"title":"Kubernetes使用ConfigMap配置应用程序（二）","text":"上一篇学习了通过args方式还是env方式都是将配置应用，配置参数硬编码在POD配置文件中，实际应用部署的过程中，我们希望配置参数和POD配置能够解藕，今天我们就看一下如何用ConfigMap配置应用。 创建一个ConfigMap 使用命令行创建 1kubectl create configmap fortune-configmap --from-literal=sleep-interval=60 创建成功以后可以通过kubectl命令查询configmap的配置。 kubectl get configmap fortune-configmap -o yaml 查询结果如下： 123456789101112131415161718192021apiVersion: v1data: sleep-interval: &quot;60&quot;kind: ConfigMapmetadata: creationTimestamp: &quot;2020-09-29T12:29:40Z&quot; managedFields: - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:data: .: {} f:sleep-interval: {} manager: kubectl-create operation: Update time: &quot;2020-09-29T12:29:40Z&quot; name: fortune-configmap namespace: default resourceVersion: &quot;2434&quot; selfLink: /api/v1/namespaces/default/configmaps/fortune-configmap uid: a6562e65-1431-47b1-b153-e4c270561a2c 使用yaml文件创建 上述查询到信息将metadata中只保留名称就可以创建一个简单的ConfigMap配置文件，使用如下命令即可通过文件创建ConfigMap kubectl create -f fortune-congfigmap.yaml 在POD文件中使用CongfigMap配置应用 使用环境变量配置应用 修改POD配置文件，使用ConfigMap配置env参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445apiVersion: v1kind: Podmetadata: name: fortune-env labels: app: fortune-envspec: containers: - name: html-gen image: 172.17.0.1:5000/fortune:env env: - name: INTERVAL valueFrom: configMapKeyRef: name: fortune-configmap key: sleep-interval volumeMounts: - name: html mountPath: /var/htdocs - name: log mountPath: /var/log/fortune - name: web-server image: 172.17.0.1:500/nginx:alpine volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 protocol: TCP - name: log-server image: 172.17.0.1:5000/nginx:log volumeMounts: - name: log mountPath: /usr/share/nginx/log readOnly: true ports: - containerPort: 8080 protocol: TCP volumes: - name: html emptyDir: {} - name: log emptyDir: {} 重新创建PODkubectl create -f fortune-pod-env.yaml， 此时再查询fortune每个60秒更新一次。实际应用部署时，也可以修改ConfigMap的配置，当新新建POD时会使用新的ConfigMap值。 使用参数配置应用 和使用环境变量配置POD类似，修改POD配置文件，使用ConfigMap配置args参数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546apiVersion: v1kind: Podmetadata: name: fortune-args labels: app: fortune-argsspec: containers: - name: html-gen image: 172.17.0.1:5000/fortune:args env: - name: INTERVAL valueFrom: configMapKeyRef: name: fortune-configmap key: sleep-interval args: [$(INTERVAL)] volumeMounts: - name: html mountPath: /var/htdocs - name: log mountPath: /var/log/fortune - name: web-server image: 172.17.0.1:500/nginx:alpine volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 protocol: TCP - name: log-server image: 172.17.0.1:5000/nginx:log volumeMounts: - name: log mountPath: /usr/share/nginx/log readOnly: true ports: - containerPort: 8080 protocol: TCP volumes: - name: html emptyDir: {} - name: log emptyDir: {} 创建PODkubectl create -f fortune-pod-args.yaml， 此时查询fortune每个60秒更新一次。 此时，如果删除旧的ConfigMap，重新配置一个新的ConfigMap，再同时删除frotune-env pod和fortune-args pod并重新新建POD时会使用新的ConfigMap值。 ConfigMap可以配置的资源 从文件、文件夹和字符创建的ConfigMap","link":"/2020/09/29/2020-09-29-20/"},{"title":"Kubernetes部署和升级应用","text":"之前文章中我们都是用POD部署应用，特别是用POD部署应用时如果要更新应用程序，必须先更新镜像（Image）/配置（ConfigMap），删除POD再重新部署应用程序才能整整的更新。Kubernetes提供了更高级的应用部署和升级方法。 使用ReplicationController部署应用 如果用ReplicationController（RC）部署的应用可以通过RC update来更新应用。 具体的kubia-rc.yaml文件如下： 12345678910111213141516171819apiVersion: v1kind: ReplicationControllermetadata: name: kubiaspec: replicas: 3 selector: app: kubia template: metadata: name: kubia labels: app: kubia spec: containers: - name: kubia image: 172.17.0.1:5000/kubia:v1 ports: - containerPort: 3000 使用kubectl create -f kubia-rc.yaml创建RC，部署成功以后即可看到根据RC的配置会产生3个副本kubectl get rc,po。 123456789kubectl get po,rcNAME READY STATUS RESTARTS AGEpod/kubia-bqszw 1/1 Running 0 62spod/kubia-c4cb9 1/1 Running 0 62spod/kubia-wxj55 1/1 Running 0 62sNAME DESIRED CURRENT READY AGEreplicationcontroller/kubia 3 3 3 62s 当前POD到到镜像版本为v1 1234567891011121314151617181920kubectl describe poName: kubia-bqszwNamespace: defaultPriority: 0Node: minikube/172.17.0.3Start Time: Wed, 14 Oct 2020 20:29:56 +0800Labels: app=kubiaAnnotations: &lt;none&gt;Status: RunningIP: 172.18.0.3IPs: IP: 172.18.0.3Controlled By: ReplicationController/kubiaContainers: kubia: Container ID: docker://ec65afaeea2e8726530863981512165bec02ceb8e953a3d6575f6ea4ad7cc3f3 Image: 172.17.0.1:5000/kubia:v1 Image ID: docker-pullable://172.17.0.1:5000/kubia@sha256:0a9705988c08da5cc4fd535f40216a7b0ef89325b594ddb97ffcbd220c6731f1... 通过kubectl set image rc/kubia kubia=172.17.0.1:5000/kubia:v2更新镜像。此时的应用程序并不会自动更新。当POD 异常或者手工删除以后RC 会自动拉起一个POD ，保证POD的副本数和RC 中配置的一致，此时新的POD 就是使用新的镜像创建应用，也就是说有的POD 使用新的镜像，有的POD 使用老的镜像。可以通过kubectl describe po查询到POD中容器的镜像版本不同。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150kubectl describe poName: kubia-c4cb9Namespace: defaultPriority: 0Node: minikube/172.17.0.3Start Time: Wed, 14 Oct 2020 20:29:56 +0800Labels: app=kubiaAnnotations: &lt;none&gt;Status: RunningIP: 172.18.0.4IPs: IP: 172.18.0.4Controlled By: ReplicationController/kubiaContainers: kubia: Container ID: docker://2b259af30a0c75987f027ac4516a7ea368774bbac4259a732f8141fdbcae376a Image: 172.17.0.1:5000/kubia:v1 Image ID: docker-pullable://172.17.0.1:5000/kubia@sha256:0a9705988c08da5cc4fd535f40216a7b0ef89325b594ddb97ffcbd220c6731f1 Port: 3000/TCP Host Port: 0/TCP State: Running Started: Wed, 14 Oct 2020 20:30:04 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-d2hsm (ro)Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: default-token-d2hsm: Type: Secret (a volume populated by a Secret) SecretName: default-token-d2hsm Optional: falseQoS Class: BestEffortNode-Selectors: &lt;none&gt;Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300sEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 6m43s default-scheduler Successfully assigned default/kubia-c4cb9 to minikube Normal Pulled 6m36s kubelet Container image &quot;172.17.0.1:5000/kubia:v1&quot; already present on machine Normal Created 6m36s kubelet Created container kubia Normal Started 6m35s kubelet Started container kubiaName: kubia-s6822 ‹--自动使用新的镜像创建新的PODNamespace: defaultPriority: 0Node: minikube/172.17.0.3Start Time: Wed, 14 Oct 2020 20:35:57 +0800Labels: app=kubiaAnnotations: &lt;none&gt;Status: RunningIP: 172.18.0.6IPs: IP: 172.18.0.6Controlled By: ReplicationController/kubiaContainers: kubia: Container ID: docker://91fd664961c798256afbfd9b2e6cd47697a817f27803812da26e28d56212371e Image: 172.17.0.1:5000/kubia:v2 Image ID: docker-pullable://172.17.0.1:5000/kubia@sha256:0709bbd6e3a34f306a16207b79b045e6a4bf33c22a3e7a88404166caee41e51f Port: 3000/TCP Host Port: 0/TCP State: Running Started: Wed, 14 Oct 2020 20:36:02 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-d2hsm (ro)Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: default-token-d2hsm: Type: Secret (a volume populated by a Secret) SecretName: default-token-d2hsm Optional: falseQoS Class: BestEffortNode-Selectors: &lt;none&gt;Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300sEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 42s default-scheduler Successfully assigned default/kubia-s6822 to minikube Normal Pulled 38s kubelet Container image &quot;172.17.0.1:5000/kubia:v2&quot; already present on machine Normal Created 37s kubelet Created container kubia Normal Started 37s kubelet Started container kubiaName: kubia-wxj55Namespace: defaultPriority: 0Node: minikube/172.17.0.3Start Time: Wed, 14 Oct 2020 20:29:56 +0800Labels: app=kubiaAnnotations: &lt;none&gt;Status: RunningIP: 172.18.0.2IPs: IP: 172.18.0.2Controlled By: ReplicationController/kubiaContainers: kubia: Container ID: docker://a5195a7ec8573d429445f7c79218372abc887d360b3564c8659b600c236c0248 Image: 172.17.0.1:5000/kubia:v1 Image ID: docker-pullable://172.17.0.1:5000/kubia@sha256:0a9705988c08da5cc4fd535f40216a7b0ef89325b594ddb97ffcbd220c6731f1 Port: 3000/TCP Host Port: 0/TCP State: Running Started: Wed, 14 Oct 2020 20:30:04 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-d2hsm (ro)Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: default-token-d2hsm: Type: Secret (a volume populated by a Secret) SecretName: default-token-d2hsm Optional: falseQoS Class: BestEffortNode-Selectors: &lt;none&gt;Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300sEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 6m44s default-scheduler Successfully assigned default/kubia-wxj55 to minikube Normal Pulled 6m36s kubelet Container image &quot;172.17.0.1:5000/kubia:v1&quot; already present on machine Normal Created 6m36s kubelet Created container kubia Normal Started 6m35s kubelet Started container kubia 使用ReplicationController部署应用，需要手工选择POD 逐一进行升级。实际部署应用过程中我们希望这个过程可以可控、且自动完成，这就需要通过更高级更高级的概念来部署应用。 使用Deployment部署应用 Kubernetes提供更高级的概念来实现应用的部署、滚动升级以及回滚。一个典型的kubernetes的应用会包含：POD、RepliciaSet以及Deployment。他们之间的关系如下： 123456789101112131415161718apiVersion: apps/v1kind: Deploymentmetadata: name: kubiaspec: replicas: 3 selector: matchLabels: app: kubia template: metadata: labels: app: kubia spec: containers: - name: kubia image: 172.17.0.1:5000/kubia:v1 还是上面的例子，这次将ReplicationController的yaml文件中kinde替换城Deployment，并另存为kubia-deploymnent.yaml，使用kubectl create -f kubia-deployment.yaml重新部署应用，部署成功以后可以功过kubectl get po,rs,deployment查询部署的应用情况。 123456789101112kubectl get po,rs,deploymentNAME READY STATUS RESTARTS AGEpod/kubia-7fc889c9c9-b7b8f 1/1 Running 1 21hpod/kubia-7fc889c9c9-lp7m8 1/1 Running 1 21hpod/kubia-7fc889c9c9-qkz9w 1/1 Running 1 21hNAME DESIRED CURRENT READY AGEreplicaset.apps/kubia-7fc889c9c9 3 3 3 21hNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/kubia 3/3 3 3 21h 通过kubectl descibe po查询到POD到详细情况如下： 123456789101112131415161718192021kubectl describe poName: kubia-7fc889c9c9-b7b8fNamespace: defaultPriority: 0Node: minikube/172.17.0.3Start Time: Tue, 13 Oct 2020 22:44:19 +0800Labels: app=kubia pod-template-hash=7fc889c9c9Annotations: &lt;none&gt;Status: RunningIP: 172.18.0.2IPs: IP: 172.18.0.2Controlled By: ReplicaSet/kubia-7fc889c9c9Containers: kubia: Container ID: docker://aa524c986c27e53d12961173a5a0adf43a3554e13aeac5fc1c5cca083da09271 Image: 172.17.0.1:5000/kubia:v1 ‹-- 镜像版本是v1 Image ID: docker-pullable://172.17.0.1:5000/kubia@sha256:0a9705988c08da5cc4fd535f40216a7b0ef89325b594ddb97ffcbd220c6731f1... 更新应用 配置更新镜像 kubectl set image deployment/kubia kubia=172.17.0.1:5000/kubia:v2 设置完成以后deployment会自动滚动升级，可以通过kubectl rollout deployment/kubia status查询升级状态，此时查询应用部署的详情可以看到PO,RS更新中或者已经更新成功。 kubectl get po,rs,deployment 其中存在2个rs，一个升级前的rs，一个是当前到rs。 12345678910111213kubectl get po,rs,deploymentNAME READY STATUS RESTARTS AGEpod/kubia-7fc889c9c9-b7b8f 1/1 Running 1 21hpod/kubia-7fc889c9c9-lp7m8 1/1 Running 1 21hpod/kubia-7fc889c9c9-qkz9w 1/1 Running 1 21hpod/kubia-84ddcd9474-bv8fl 0/1 ContainerCreating 0 3s ‹-- 新建PODNAME DESIRED CURRENT READY AGEreplicaset.apps/kubia-7fc889c9c9 3 3 3 21h ‹-- 升级前的rsreplicaset.apps/kubia-84ddcd9474 1 1 0 4s ‹-- 当前的rsNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/kubia 3/3 1 3 21h 查询POD详细信息，可以看到新建到POD已经更新为新到镜像。 1234567891011121314151617181920kubectl describe po kubia-84ddcd9474-bv8fl ‹-- 新建PODName: kubia-84ddcd9474-bv8flNamespace: defaultPriority: 0Node: minikube/172.17.0.3Start Time: Wed, 14 Oct 2020 20:19:12 +0800Labels: app=kubia pod-template-hash=84ddcd9474Annotations: &lt;none&gt;Status: RunningIP: 172.18.0.6IPs: IP: 172.18.0.6Controlled By: ReplicaSet/kubia-84ddcd9474Containers: kubia: Container ID: docker://3de190659e28bebcde082b287c7c4c434ab706c08654f6d1c7db3db455304508 Image: 172.17.0.1:5000/kubia:v2 ‹-- 镜像版本是v2 Image ID: docker-pullable://172.17.0.1:5000/kubia@sha256:0709bbd6e3a34f306a16207b79b045e6a4bf33c22a3e7a88404166caee41e51f 管理升级 此时如果使用kubectl rollout undo deployment/kubia 即可全部回滚应用，可以通过kubectl rollout pause/resume/restart/history等控制滚动升级过程（如果测试过程中难以观察到升级过程，可以讲deployment中副本数量调高）。 此外，也可以使用StatefulSet部署有状态应用。StatefulSet和Deployment最大的区别是为每个副本POD实例提供店里存储，可以保证POD副本有固定的名字和主机，可以按照预期的顺序启停POD副本。","link":"/2020/10/14/2020-10-14-19/"},{"title":"minikube addons enable ingress","text":"由于大家都知道到原因，国内无法直接访问gcr.io和quay.io很多Kubernetes相关镜像无法从国内下载，网上很多大神也给出了薅aliyun羊毛的方案，我自己也试了几次也总是不能成功，使用aliyun提供minikube的版本也总是无法启动ingress。 通过查看启动ingress失败的POD信息发现是无法下载使用到镜像，于是按照网络指导按照如下步骤提前下载镜像到minikube节点，再启动ingress即可成功，具体操作如下： 查询minikube版本对应的ingress镜像版本 使用kubectl get po -A查询ingress对应POD 12345678910111213kubectl get po -ANAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-546565776c-xgggd 1/1 Running 0 27mkube-system etcd-minikube 1/1 Running 0 27mkube-system ingress-nginx-admission-create-d9dtl 0/1 Completed 0 28skube-system ingress-nginx-admission-patch-x67q7 0/1 Completed 1 28skube-system ingress-nginx-controller-7bb4c67d67-hp5c7 0/1 ContainerCreating 0 28skube-system kube-apiserver-minikube 1/1 Running 0 27mkube-system kube-controller-manager-minikube 1/1 Running 0 27mkube-system kube-proxy-7wbct 1/1 Running 0 27mkube-system kube-scheduler-minikube 1/1 Running 0 27mkube-system storage-provisioner 1/1 Running 0 27m 其中名字中包含ingress就是启动ingress新建到POD。 再使用kubectl describe po ingress-nginx-xxx --namespace kube-system查询具体的失败信息，即可查询到失败原因为：获取镜像失败/超时。由于minikube 1.12.0版本以上的ingress镜像目前在阿里云上也无法下载，我们将minikube的版本切换到1.12.0版本，此时查询到的ingress插件依赖镜像信息如下： 12quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.32.0jettech/kube-webhook-certgen:v1.2.0 手动安装ingress镜像 使用minikube ssh登录到minikube的节点上，再动过docker命令手工pull镜像。 123docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:0.32.0docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:0.32.0 quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.32.0docker pull jettech/kube-webhook-certgen:v1.2.0 quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.32.0 镜像可以由aliyun的镜像替代，再重新Tag成原有镜像。 再次启用ingress 上述操作均成功以后可以再次启动ingress插件即可秒成功 ：）","link":"/2020/10/14/2020-10-14-23/"},{"title":"配置Manjaro Linux上ibus-rime输入法","text":"在Manjaro系统中不能直接通过ibus-setup设置ibus-rime显示模式为水平模式（可能是Manjaro的bug）只能设置字体和文字大小。可以通过直接修改ibus-rime配置文件配置想要的显示方式。 ibus-rime的配置文件默认在~/.config/ibus/rime/build/目录下，直接将horizontal配置项修改成true即可。 其他的ibus配置可以参考https://wiki.archlinux.org/title/IBus","link":"/2021/08/09/2021-08-08-09/"},{"title":"使用pandoc生成PPT常用命令","text":"使用markdown + marp或者markdown + revealjs可以写PPT。使文档写作过程只专注于写作本身而不是各种格式。其实第一次还是要将常用的格式做好调试（主要是写一些常用的css文件自定义样式），后续则可以在markdown-&gt;html/PDF/docx/pptx/ebook间随意转换了。 以下主要记录几个常用命令，完整的pandoc手册可以参考：https://pandoc.org/MANUAL.html markdown 2 pptx pandoc mark.md -o mark.pptx --reference-doc=template.potx mardown 2 revealjs pandoc -t revealjs mark.md -o mark.html --self-contained -V revealjs-url=./reveal.js/ --css=custom.css -t 参数还可以设置成s5, slidy, slideous, dzslides; -V revealjs-url 可以制定本地目录reveal.js, 将https://github.com/hakimel/reveal.js下载本地即可; -css 可以制定css附件，通过定制css文件可以调整显示样式。 对于revealjs可以在文件中设置width和height调整显示大小 markdown文件示例文件如下： 1234567891011121314151617181920---title: 使用pandoc生成PPT常用命令theme: whitewidth: 1920height: 1280author:- authordate: 2021-09-14---# markdown2pptx`pandoc mark.md -o mark.pptx --reference-doc=template.potx`---# markdown2revealjs`pandoc -t revealjs mark.md -o mark.html --self-contained -V revealjs-url=./reveal.js/ --css=custom.css` css文件示例 123.reveal h1{ color:olivedrab}","link":"/2021/09/14/2021-09-13-23/"},{"title":"Manjaro安装vscode和edge","text":"这个方法是从archlinux build源手工安装软件。首先需要安装基础的软件包，再下载源编译和安装。 安装基础包(只需要做一次) sudo pacman -S --needed git base-devel 下载编译源 vscode git clone https://aur.archlinux.org/visual-studio-code-bin.git edge git clone https://aur.archlinux.org/microsoft-edge-stable-bin.git 如果不知道具体的编译源路径可以从https://aur.archlinux.org/packages搜索 编译并安装 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869~/Downloads cd microsoft-edge-stable-bin~/Downloads/microsoft-edge-stable-bin makepkg -si==&gt; 正在创建软件包：microsoft-edge-stable-bin 105.0.1343.42-1 (2022年09月17日 星期六 22时29分04秒)==&gt; 正在检查运行时依赖关系...==&gt; 正在检查编译时依赖关系==&gt; 获取源代码... 正在下载 microsoft-edge-stable_105.0.1343.42-1_amd64.deb... Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 127M 100 127M 0 0 20.0M 0 0:00:06 0:00:06 --:--:-- 22.3M 找到 microsoft-edge-stable.sh 找到 Microsoft Standard Application License Terms - Standalone (free) Use Terms.pdf==&gt; 正在验证 source 文件，使用sha256sums... microsoft-edge-stable_105.0.1343.42-1_amd64.deb ... 通过 microsoft-edge-stable.sh ... 通过 Microsoft Standard Application License Terms - Standalone (free) Use Terms.pdf ... 通过==&gt; 正在释放源码... 正在解压缩 microsoft-edge-stable_105.0.1343.42-1_amd64.deb，使用 bsdtar==&gt; 正在进入 fakeroot 环境...==&gt; 正在开始 package()...==&gt; 正在清理安装... 正在删除 libtool 文件... 正在清除不打算要的文件... 正在移除静态库文件...==&gt; 正在检查打包问题...==&gt; 正在构建软件包&quot;microsoft-edge-stable-bin&quot;... 正在生成 .PKGINFO 文件... 正在生成 .BUILDINFO 文件... 正在生成 .MTREE 文件... 正在压缩软件包...==&gt; 正在离开 fakeroot 环境。==&gt; 完成创建：microsoft-edge-stable-bin 105.0.1343.42-1 (2022年09月17日 星期六 22时29分27秒)==&gt; 正在安装软件包 microsoft-edge-stable-bin，使用 pacman -U...正在加载软件包...正在解析依赖关系...正在查找软件包冲突...软件包 (1) microsoft-edge-stable-bin-105.0.1343.42-1全部安装大小： 445.96 MiB:: 进行安装吗？ [Y/n] Y(1/1) 正在检查密钥环里的密钥 [####################################] 100%(1/1) 正在检查软件包完整性 [####################################] 100%(1/1) 正在加载软件包文件 [####################################] 100%(1/1) 正在检查文件冲突 [####################################] 100%(1/1) 正在检查可用存储空间 [####################################] 100%:: 正在处理软件包的变化...(1/1) 正在安装 microsoft-edge-stable-bin [####################################] 100%microsoft-edge-stable-bin 的可选依赖 libpipewire02: WebRTC desktop sharing under Wayland kdialog: for file dialogs in KDE gnome-keyring: for storing passwords in GNOME keyring kwallet: for storing passwords in KWallet [已安装] libunity: for download progress on KDE ttf-liberation: fix fonts for some PDFs - CRBug #369991 [已安装] xdg-utils [已安装]:: 正在运行事务后钩子函数...(1/4) Arming ConditionNeedsUpdate...(2/4) Refreshing PackageKit...(3/4) Updating icon theme caches...(4/4) Updating the desktop file MIME type cache...~/Downloads/microsoft-edge-stable-bin","link":"/2022/09/17/2022-09-17-20/"},{"title":"Manjaro下使用grub-customizer修改grub菜单","text":"Manjaro下没有grub-customizer，可以通过编译源码安装安装。再使用grub-customizer修改grub菜单。 下载源码 https://launchpad.net/grub-customizer 编译并安装 解压缩下载的源码文件 tar -xvf grub-customizer_5.2.2.tar.gz 进入到源码的REAME文件，查看源码编译指导，从编译指导中可以查看到依赖项目 由于我使用的是Manjaro KDE版本，只需要单独安装依赖的gtkmm包以及cmake和make 安装依赖的包 1234sudo pacman -S gtkmm3sudo pacman -S cmakesudo pacman -S makesudo pacman -S pkg-config 编译grub-customizer cmake . &amp;&amp; make 安装grub-customizer sudo make install grub-customizer 修改grub菜单 sudo grub-customizer，打开grub-customizer修改或者删除不需要的启动项。 注意 在Manjaro 21中务必要保留最后一个内存测试的选项‘Memory Tester’，否则更新grub时会报错语法错误。","link":"/2022/09/18/2022-09-18-20/"},{"title":"Manjaro系统中安装为fcitx5安装主题","text":"安装fcitx5以及中文输入法 123sudo pacman -S fcitx5-imsudo pacman -S fcitx5-chinese-addonssudo pacman -S fcitx5-rime 编辑/etc/environment文件 在文件增加如下信息: 123GTK_IM_MODULE=fcitxQT_IM_MODULE=fcitxXMODIFIERS=@im=fcitx 安装输入法主题 执行命令pacman -S fcitx5-material-color 安装主题 修改配置文件 修改~/.config/fcitx5/conf/classicui.conf文件 1234567891011# 垂直候选列表Vertical Candidate List=False# 按屏幕 DPI 使用PerScreenDPI=True# Font (设置成你喜欢的字体)Font=&quot;Noto Sans Regular 14&quot;# 主题Theme=Material-Color-Teal 可选的颜色主题如下 12345678910Material-Color-PinkMaterial-Color-BlueMaterial-Color-BrownMaterial-Color-DeepPurpleMaterial-Color-IndigoMaterial-Color-RedMaterial-Color-TealMaterial-Color-BlackMaterial-Color-OrangeMaterial-Color-SakuraPink 参考链接：https://wiki.archlinux.org/title/Fcitx5","link":"/2022/09/20/2022-09-19-22/"},{"title":"一个典型的混合云弹性伸缩架构","text":"一个典型的混合云弹性伸缩架构","link":"/2022/09/20/2022-09-20-22/"},{"title":"Archlinux设置KDE中文不全和Konsole中文乱码问题","text":"安装Archlinux时如果使用英文界面安装，安装成功后，即使设置了中文语言KDE仍有关机界面、应用程序菜单仍有英文。可以参考：https://wiki.archlinux.org/title/Localization/Simplified_Chinese设置。 修改/etc/locale.gen文件，增加zh_CN.UTF-8 UTF-8（或者取消掉#注释）； 修改~/.bashrc文件，增加如下描述 12export LANG=zh_CN.UTF-8export LANGUAGE=zh_CN:en_US 如果只修改/etc/locale.genSDDM登录界面仍然是英文，此时需要修改/etc/locale.conf文件，首先备份此文件，只保留LANG=zh_CN.UTF-8其余的均删除。 注意 archlinux 官方wiki说明了修改/etc/locale.conf可能会导致问题，具体描述为“It is not recommended to set a global Chinese locale in /etc/locale.conf because it causes tty to display garbled characters.”，此修改可能导致一些系统脚本处理异常，如果介意可以不做3步。","link":"/2022/09/25/2022-09-20-25/"},{"title":"在WSL2中安装Arch Linux","text":"公司办公PC是Windows，日常又会使用到一些linux做一些实验性工作，今天无意间看到了在WSL安装Archlinux。记录了一下安装过程。 下载安装Arch Linux 以下操作均在windows进行 1. 从github上下载Archlinux的二进制文件，项目地址：https://github.com/yuk7/ArchWSL，下载Arch.zip 在Windows上解压缩Arch.zip会得到两个文件： 12Arch.exerootfs.tar 执行Arch.exe文件则会自动完成安装工作 添加管理员账户 以下操作均在wsl-archlinux进行。 由于安装好的Archlinux默认使用root用户登录，passwd 修改root用户密码 创建一个非root用户 12useradd -m -G wheel -s /bin/bash &lt;username&gt;passwd &lt;username&gt; 将新增用户添加到sudo(wheel)组 1sudo nano /etc/sudouers 取消掉%wheel ALL=(AKK) ALL注释 设置Arch Linux默认登录用户 以下在Windows上进行 1. 在cmd上执行Arch.exe config --default-user &lt;username&gt;，其中上一步在archlinux创建用户名。 此时在cmd上执行wsl -d arch即可使用默认新增用户进入到Archlinux中，如果安装了Windows terminal也可以直接使用新建标签按钮从Arch选项进入到Archlinux。","link":"/2022/09/27/2022-09-20-27/"},{"title":"纵横大数据主要观点","text":"大数据时代企业数据特征 大数据时代企业大数据标为 “大、 广、联”特征，“大”指的是数据量大，“广”指的是数据涉及各类不同胸痛，不同类型大数据，例如：IoT数据、日志数据等，“联”指的是企业内外部数据关联、不同业务部门大数据关联。 数据处理大要求没有变化 大数据时代虽然数据量激增，但是企业对数据处理的要求没有变化，甚至要求更高。主要是要求高可靠、高负载、 低成本。 解决单一系统处理问题 为了应对大数据大挑战，业界采用了而分布式+并行大处理方式，出现了分布式关系型数据库、NoSQL数据库、Hadoop等技术。此外，传统数据库厂商也推出了一体机数据产品。 解决多系统融合问题 大数据时代希望通过数据实现 “数据驱动业务和运营优化”，业务上需要打通不同大业务系统以及内外部数据；技术上要求关系型数据库和NoSQL数据库产品技术融合；对上提供统一API（或者SQL）简化应用开发，对下需要利用基于云IaaS基础设施实现高弹性和低成本。 大数据本质 大数据是云计算时代企业管理处理数据的方式，大数据的本质是云计算数据基础设施。研究大数据问题大实施是实现 “数据驱动业务”，研究包括业务和技术本身。 大数据系统包括关系型数据处理系统和NoSQL数据库处理系统。未来关系型和NoSQL两种技术会融合，同时企业的数据会整合（即构建统一的数据湖）。 现代企业数据处理面临的挑战 传统数据业务有两个特点 数据量可预估（如典型的及融合电信业务系统，客户和数据量是可预估的） 可以通过技术手段对高频、低频数据采取不同的策略（例如：将低频数据从在线系统中卸载） 企业新的业务是面向社会、交互式业务，会产生海量不可预估的数据（例如：传感器、日志数据等），原有业务系统不会产生或者丢弃的数据 关系型数据库要先设计模式（schema），一般遵循范式建模，NoSQL数据库不要求强制建模，可以根据业务发展调整数据模型，且不想要大规模修改数据库设计 为什么要引入NoSQL数据库 关系型数据库存储高价值数据，数据处理成本高、大规模分析效率低（数据模式和存储是隔离的）；传统关系型解决数据库系统的瓶颈主要是通过scale up（通常只能临时解决问题），也可以通过有限的scale out解决问题，但规模受限（例如：Oracle RAC线性比不佳，TeraData最大的商用规模大约为600节点）；厂商也通过一体机（通常是利用InfiniBand网络，NvME SSD等）解决性能问题。 NoSQL数据库存储低价值的贴源数据（可根据业务需求重复分析），NoSQL数据库通常有如下优势： 低成本水平扩展 处理特定场景有优势（例如：图数据库、时空数据库、文档数据库） 不要求遵循强制模式（schema），可以灵活调整设计模式 存储性能高，部分数据库的设计可直接读取存储 扩展阅读 范式建模 1NF要求所有数据必须是不可再分的原子数据 2NF在1NF基础上要求所有属性必须依赖主键，实现了所有行数据不冗余 3NF在2NF基础上要求属性不能传递依赖主属性，实现列数据没有冗余。","link":"/2022/10/06/2022-10-06-20/"},{"title":"纵横大数据主要观点（二）","text":"分布式关系型数据库典型的架构 Share-Nothing MPPDB一般都是此架构，主要是将数据拆分存储到不同的节点上，在各自节点上独立读写数据，正因为如此，此架构只适合OLAP业务，如果进行表关联操作时仍会进行网络节点之间的数据迁移与交换工作，同样的网络会成为MPPDB 水平扩展的瓶颈。TeraData目前最大商用规模大约600节点。 Share-Disk 典型的应用是Oracle RAC，不同于传统的HA架构，ShareDisk架构中的每个节点都是工作节点，独立处理业务。由于是ShareDisk架构，读写磁盘就会出现冲突，会产生大量的存储网络流量，通常存储网络的流量会因为数据库节点规模增加变成瓶颈 OLTP和OLAP 通常部署在两套系统中主要原因是数据库系统追求的高TPS，OLTP追求的是高并发、随机读写，要保持交易十五的ACID 特性，维护强大的数据库日志，目前实现OLTP单点能力（主机平台+高端IO存储）。OLAP追求的是批量操作、高并发读操作，技术上主要解决很好的分配与管理各种资源（即资源的精细化管理）。 关于Join操作，跨表聚合操作，对于OLTP数据库需要大量的IO操作将表数据读取到内存进行操作；而MPP数据库本身就是根据某个键值对数据进行分布式存储，相当于提前为多表Join操作做了很多工作。OLTP通常是通过hash join进行优化，OLAP是通过分布式join。 NoSQL数据库 NoSQL数据库是随着互联网应用发展起来的（是新兴数据库产品，并不是完全的新技术），主要是用来处理半结构化数据/非结构化数据。NewSQL是关系型数据库联邦（主要代表是VoltDB），内存数据库集群。 NewSQL数据库 实现NewSQL通常是采用数据库“联邦”来实现。主要就是采用“垂直分库“，”水平分表”。分库分表以后，按照分库分表的策略会将数据分散到不同的物理设备上（只有这样才能增加数据库的处理能力），这就导致了应用会感知到数据在不同的数据库服务器上。此外，还可以通过读写分离来增加。 企业数据库变化的路径 小型数据库-&gt;大型数据库-&gt;现有数据库扩展 1. 小型数据库：MySQL、SQL Server、PostgreSQL 2. 大型数据库：Oracle、DB2甚至是基于大机（MainFrame）数据库解决方案 3. 对现有数据库管理系统进行扩展（通常是已经上了Oracle、DB2等大型数据库的情况） - 直接scale up - 采用厂商提供高阶方案，例如：oracle rac - 分库分表 - 读写分离 垂直分库 将原来在中心物理数据库中不同类型database拆分到不同的物理数据库（也就是把原来数据库的关联操作要改成两个数据中心之间的关联消息通信服务） 分库是业务人员需要对数据库进行重新设计优化，去掉不必要、复杂的关联操作 水平分表 按照独立数据库中的某一个大表按照某种方式拆分成“子表”，通常是按照某一列或者多列值进行均分或者按照哈希算法分割 将子表部署在不同物理数据库服务器中以提升整体数据库性能 读写分离 将一个中心库分成两类库，一类用于处理读操作，一类用于处理写操作 需要增加一个读写分离代理来专门完成该任务，屏蔽对应用的影响 读写分离数据库中数据是完全一致的 可以设置读操作一致性规则，例如要等到从R（大于等于1）个读库读到的数据库一致时才返回读操作结果 写操作的数据库必须实时或者准实时将数据同步到读库。 小结 1. 分库分表和读写分离是相辅相成，可单独实施也可以一起实施。分库包容了分表（一般在实施分库的基础上再实施分表），分库分表和读写分离是平行的，可以同时实施。 2. 数据库联邦牺牲即时一致性，但保证了最终的一致性（CAP原则中，牺牲了C），也就意味着实际应用中弱化了的事务和关联性。","link":"/2022/10/13/2022-10-13-21/"},{"title":"纵横大数据主要观点（三）","text":"什么是数据库联邦 作者引入了一个数据库“联邦”的概念，是为了避免和数据库“集群”概念混淆。 关系型数据库联邦是数据库设计的一种架构：将一组互相独立的关系型数据库用网络连接起来协同工作，综合采用各种技术（分库分表、读写分离）以达到更强的数据管理与服务能力，提供更加的性能、更大的容量与更多的并发用户数。 一个联邦架构的数据系统需要提供以下关键服务 分布服务：确定由那个子数据库来执行相关的服务 协调服务：数据库节点之间交互数据处理，统一调度控制等 监控与管理服务：对分布式节点进行监控以及统一管理（例如节点升级、重启等） 消息服务：跨节点数据处理时需要用消息机制传递数据 联邦的元数据库 有两种思路： 1. 在联邦数据库中迁移一个元数据系统，例如联邦MySQL数据库中增加一个HA MySQL来保存元数据，此时这个元数据数据库就成为新的瓶颈 2. 将分库分表信息嵌入到应用中，应用课感知到分开分表信息，避免由数据库系统自身再次行程单点故障或者瓶颈 数据库联邦的应用实践 OceanBase GaussDB for MySQL GaussDB for OpenGauss 数据库联邦、NoSQL与主流数据库 一句话：八仙过海、 各显神通，每个类型的数据均有自己的擅长的领域，可综合使用各类技术。 互联网企业如何解决问题 互联网业务的复杂性、不同业务之间的关联性没有金融、电信行业复杂方便实现分库、分表策略 即使是互联网企业在进行联邦数据库技术时应用也进行了改造，去除了不表要的表间的关联 互联网业务本身对数据强制性要求也低于金融、电信产品 互联网企业都有庞大的IT团队，在标准的软件包不能满足业务时，都是通过自研来满足业务，甚至可以说互联网企业本身就是一个IT企业，这对于传统的金融、 电信行业是是不可能实现的5. 大多数企业不能也不应该把自己变成一个IT企业，仍然需要专业的IT软件及服务来解决问题。","link":"/2022/10/17/2022-10-17-15/"},{"title":"SOA架构和微服务架构的区别","text":"什么是SOA架构 企业范围内的应用程序或者服务开发的方法，目的是复用组件和服务。在SOA架构中每个服务（service）都会提供独立的代码和数据来实现特定的企业业务功能（business function）。各个服务之间是松藕荷的，提供接口通过企业总线（ESB）进行集成；从而减少服务更新导致的大量的集成工作；在这种架构下，如果服务出现问题仍会影响到关联的服务。 实践中XML数据是SOA架构重要的组成部分，基于XML的SOA应用程序可以构建web服务。在SOA架构出现在大约1990年代末，在此之前单体应用之间的集成是点对点集成，每增加一个应用都需要重新做开发和集成测试。 SOA架构四中不同的服务类型 Functional services（功能服务）：用于表达业务逻辑 Enterprise services（企业服务）：用于实现功能（functional） Application services（应用服务）：用于开发部署App infrastructure services （基础设施服务）：应用后端的基础服务（例如：认证鉴权、安全等） 每种服务都包含下三个组件 接口（interface）：定义了服务提供者如何执行来自消费者的请求 协议（contract）：定义了服务提供者和消费者之间的交换方式 实现（implementation）：服务的具体实现代码 什么是微服务 和SOA架构类似，微服务也是需要解决松耦合和复用问题，微服务之间是相互独立。微服务是高内聚的，自己管理代码和数据。微服务是应用层级的（非企业层级）微服务之间通过API进行通信，实现一个特定的业务功能。微服务架构可以实现更加敏捷、扩展性和弹性的应用。Java语言是实现微服务的首选语言，其次是Golang和Python。 微服务是真正的云原生架构，通常运行在容器中（容器更便于实现弹性、便携的portable、独立的服务）。 微服务和SOA架构的主要不同：范围 SOA架构和微服架构最大的不同是范围不同。SOA架构针对的是企业业务层级，每个服务对应一个企业业务，每个业务之间通过企业总线（ESB）进行数据交换；微服是针对应用层级的，微服务之间是直接通信的。 复用 SOA架构是企业级的组件组件和服务（针对特定企业级业务功能）复用。 微服务架构更是代码层级的复用，不同组件之间通过代码copy复用共性的内容，各自独立的维护。 调用机制 SOA架构通过RESTful APIs实现同步调用 微服务通过事件机制（发布/订阅）实现交互，减少微服务之间的耦合，便于实现独立的变更、弹性伸缩等。 数据 SOA架构设计的目标之一就是需要同步获取更新主数据源，从而减少数据同步带来的复杂性。 微服务架构则需要自己维护本地数据，且确保这些数据与其他微服务或者应用独立，即使这些数据在其他微服务中仍然重复存在。这带来一定的复杂性，这就需要平衡敏捷性和性能，这也被认为是可接受的实现。 其他SOA架构和微服务架构的不同 通信方式：微服务架构每个服务是独立开发的，可以有自己的通信协议；SOA架构必须要使用ESB管理和协调。 互操作性：微服务保持简单，通常只支持轻量化的消息机制，例如：HTTP/REST/JMS；SOA架构则支持多种类型的协议如：SOAP/AMQP/MSMQ等 服务粒度：微服务是聚焦做好一件事，同样的SOA架构中服务也类似，但是服务粒度是一个企业级业务功能 迭代速度：微服务快与SOA架构的服务 服务治理：SOA架构会提供统一的服务治理方案；微服务则不会提供统一服务之类方案便于各微服务有更大灵活性，促使组织之间协作 存储：SOA架构通常会为所有服务提供一个统一的存储层；微服务则会专门为需要他的服务提供一个专属存储或者数据库 SOA架构和微服务架构那个更适合你？ 针对大型的企业级应用仍然保持SOA架构，针对小型应用可以使用微服务架构；也可以将两者结合起来，企业级超大型应用采用SOA架构，其中的某一个子应用可以采用微服务架构。 参考链接 https://www.ibm.com/cloud/blog/soa-vs-microservices","link":"/2022/11/25/2022-10-17-22/"},{"title":"一个基于华为云ServiceStage简单的CI&#x2F;CD过程","text":"ServiceStage中的概念 App：App中包含了不同的组件，在ServiceStage中𨈖一的应用组件是微服务组件； 组件：组件能够独立实现特定功能，可独立开发、测试、运行以及部署； 环境：部署App的一组计算、存储、网络基础设施合集，包括：VPC、ECS、CCE、CCI以及RDS、DSCS等，同一个环境内部网络是互通的；通常可以定义多种环境，例如：开发环境、测试环境、生产环境等。 ServiceStage的两种应用构建方式 从源码构建 从二进制包构建 具体构建过程如下：","link":"/2022/10/18/2022-10-18-21/"},{"title":"Archinux配置Proxy","text":"在.bashrc文件中增加如下配置 12345export http_proxy= http://username:password@hostname:port/ export https_proxy=$http_proxy export ftp_proxy=$http_proxyexport rsync_proxy=$http_proxyexport no_proxy=&quot;localhost,127.0.0.1,localaddress,.localdomain.com&quot; 其中username和password是proxy账号和密码 如果Proxy中密码有是特殊字符需要进行转码，具体转换规则参考：https://baike.baidu.com/item/URL%E7%BC%96%E7%A0%81/3703727 ## 解決非root账号设置Proxy后sudo命令不会生效 编辑/etc/sudoers.d/05_proxy 文件，增加如下配置 1Defaults env_keep += &quot;*_proxy *_PROXY&quot; 参考链接 https://wiki.archlinux.org/title/Proxy_server","link":"/2022/10/28/2022-10-28-21/"},{"title":"分辨率和像素","text":"像素 屏幕像素 屏幕上物理像素点大小（通常用英寸衡量） 数码像素 没有物理尺寸大小 指的是数码图有多少像素（pixel）点 分辨率 概念——以下均译作分辨率 resolution：图像分辨率 PPI：1英寸屏幕显示的密度 DPI：1英寸打印点点密度 PPI和数码图像分辨率的关系 显示时没有直接关系 如果数码图像要100%显示 图像分辨率 = PPI，图像占满整个屏幕 图像分辨率 &gt; PPI，显示时图像只占屏幕一部分 图像分辨率 &lt; PPI，只能显示部分图像 DPI和数据库图像分辨率的关系 优先由图像分辨率决定 图像分辨率越高，打印越精细 同一个图像打印在同一大小纸张，DPI越高打印越精细 参考思维导图","link":"/2022/11/05/2022-11-05-19/"},{"title":"光学系统景深和计算公式","text":"景深、焦距和拍摄距离的关系 弥散圆 在焦点前后各有一个容许弥散圆，这两个弥散圆之间的距离就叫景深(depth of field)，即：在被摄主体(对焦点)前后，其影像仍然有一段清晰范围的，就是景深。换言之，被摄体的前后纵深，呈现在底片面的影象模糊度，都在容许弥散圆的限定范围内。 通常情况下，肉眼分辨率为二千分之一至五千分之一。人眼在明视距离（眼睛正前方30厘米）能够分辨的最小的物体大约为0.125mm。所以，弥散圆放大在7寸照片（这是个常用尺寸）也只能是0.125mm以内，也就是图像对角线长度的1/1730左右。 弥散圆直径的计算 这个1/1730左右的容许弥散圆大小对于任何大小的底片或者CCD都适用，因为它们放大出来的7寸照片，都可以将弥散圆控制在0.125mm。所以蔡斯公司制定的标准就是弥散圆直径=1/1730底片对角线长度。 m是CMOS芯片尺寸，由于历史原因1英寸底为16mm。 例如：1/1.8\" 的CMOS允许弥散圆直径是： mm 景深的示意图 超焦距 当远景深被扩大到无穷远时，从焦点到镜头中心的距离即是超焦距（英语：Hyperfocal distance，亦称泛焦距离）；通过将相机对焦在超焦距上可以获得给定f值下的最大景深。让对焦距离超过超焦距并不会使远景深增加（因为它已经被扩展到了无穷远），但这样却会缩短近景深，进而使完整的景深缩小，所以一些摄影师认为这样做会浪费景深。然而，这个结论是基于近处和远处的模糊圆一样大得出的，亦有摄影师认为，远处的物体在照片上较实际尺寸的比例偏小，因此若远处的物体是照片表现的主体，需要保证更小的模糊圆才能让观众感到清晰，因此对焦时超过超焦距靠近无穷远是合理的。 代表镜头的焦距，代表镜头的光圈值，而 代表的特定的胶卷格式 模糊圈的直径，超焦距为可由下式描述： 景深的计算公式 光圈直径 &gt; 其中是焦距，是设定的光圈值（2.8，4，5.6等） 光学透镜成像公式 后物体的成像 前物体的成像 根据以上六组关系客户得出如下关系 令无穷大，求 将超焦距公式代和关系式即可得到： 此公式对于中长距离和近距离一律适用。例如：将镜头对焦于，代入上式得： 说明 - 镜头光圈 光圈越大，景深越小；光圈越小，景深越大； - 镜头焦距 镜头焦距越长，景深越小；焦距越短，景深越大； - 拍摄距离 距离越远，景深越大；距离越近，景深越小。 参考信息 维基百科：景深 知乎：弥散圆直径计算","link":"/2022/11/21/2022-11-21-20/"},{"title":"摄像机中的宽动态","text":"什么是宽动态 宽动态是在非常强烈的对比下让摄像机看到影像特色而运用的一种技术。 通常有强光源的场景下，强光照射的区域和阴影区域会有非常大的亮度区别，摄像机输出图像会出现明亮区（过曝导致的白色区域）和黑暗区（曝光不足导致的黑色区域）；摄像机在同一场景下，能够支持的最亮和最暗局限就是“动态范围”。 典型的环境与照度 参考环境 大概照度 参照环境 大概照度 夏日阳光 100000lux 室内日光灯 100lux 阴天室外 10000lux 黄昏室内 10lux 距离60W台灯60cm桌面 300lux 夜间路灯 0.1lux 假设再酒店大堂中央从室内向室外拍摄，该场景下需要支持的动态范围大概为100:1（参考第一行），而一般相机动态范围大概是3:1。 不同相机工作的照度 普通型：1~300lux 月光型：0.1lux 星光型：0.01lux 红外型：在没有可见光的情况下仍可以工作 摄像机的宽动态范围计算 宽动态范定义 dB是一个比值，即摄像机能够是被的最亮部分和最暗部分的照度比值。 宽动态计算公式 V2：最强照度，V1：最弱照度","link":"/2022/11/24/2022-11-24-11/"},{"title":"什么是白平衡","text":"一些基本概念 白平衡 白平衡是通过对白色被摄物的颜色还原（产生纯白的色彩效果），进而达到其他物体色彩准确还原的一种数字图像色彩处理的计算方法。 黑体 黑体（Black body），是一个理想化的物体，它能够吸收外来的全部电磁辐射，并且不会有任何的反射与透射。换句话说，黑体对于任何波长的电磁波的吸收系数为1，透射系数为0。 物理学家以此作为热辐射研究的标准物体。它能够完全吸收外来的全部电磁辐射，并且不会有任何的反射与透射，这种物体就是绝对黑体，简称黑体。 在室温下，黑体辐射的能量集中在长波电磁辐射和远红外波段，当黑体温度到几百摄氏度之后，黑体开始发出可见光。 黑体辐射出来的光线称为黑体辐射，黑体单位表面积的辐射功率P与其温度的四次方成正比，即： 式中称为斯特藩-玻尔兹曼常数，又称为斯特藩常数。 色温 色温是表示光线中包含颜色成分的一个计量单位。从理论上讲，色温是指绝对黑体从绝对零度( -273℃)开始加温后所呈现的颜色。黑体在受热后,逐渐由黑变红,转黄,发白,最后发出蓝色光。当加热到一定的温度，黑体发出的光所含的光谱成分，就称为这一温度下的色温，计量单位为“K” （开尔文）。 色温越高光色越偏蓝；色温越低则偏红。 相机白平衡的工作原理 摄像机内部有三个CCD电子耦合元件，他们分别感受蓝色、绿色、红色的光线，在预置情况下这三个感光电路电子放大比例是相同的，为1：1：1的关系，白平衡的调整就是根据被调校的景物改变了这种比例关系。比如被调校景物的蓝、绿、红色光的比例关系是2：1：1（蓝光比例多，色温偏高），那么白平衡调整后的比例关系为1：2：2，调整后的电路放大比例中明显蓝的比例减少，增加了绿和红的比例，这样被调校景物通过白平衡调整电路到所拍摄的影像，蓝、绿、红的比例才会相同。也就是说如果被调校的白色偏一点蓝，那么白平衡调整就改变正常的比例关系减弱蓝电路的放大，同时增加绿和红的比例，使所成影像依然为白色。 真正的影像结果是偏蓝还是偏红不仅仅取决于照相机内的色温，还取决于拍摄现场的色温，而拍摄效果是机内色温与现场色温的差值决定的。在这里我们可以直接牢记这一使用规律：机内色温高于现场色温，画面色调偏红；机内色温低于现场色温，画面色调偏蓝；机内色温等于现场色温，画面色调正常。 白平衡产生的原因及矫正 Camera感光元件作为单纯的光电转换采集电子元件，将物体反射到感光元件的直接结果不经处理的成像出来。因此在不同光源下白色物体成像在Sensor上时，信号呈现出来的结果RGB比例会有所差异。 白平衡算法的核心是判断图像的色温，是在白天、 晚上、室内、是我还是烈日、夕阳等。 白平衡的流程 标定-》统计-》校正 典型自动白平衡算法 灰度世界 完美反射 动态阈值 白点法 场景检测：人脸、 绿植、蓝天，基于检测到物体，根据物体的颜色调整白平衡 基于机器学习：先根据形状、纹理识别物体，（依据经验实现色彩恒常性）再根据物体调整白平衡；例如：白纸是白色。此方法是机器学习基于人类大脑工作方式矫正的。 扩展阅读 什么是纹理 纹理是由物体表面的无力属性的多样性而造成的，物理属性不同啧表示某个特定表面特征的灰度或者颜色信息不同，不同的无力表面会产生不同的问题里图像。 纹理的三个主要标志 某种局部的序列行在笔盖序列更大的区域内不断重复 序列是有基本元素飞随机排列组成的 各部分大致是均匀的同体，在纹理区域内的热和地方都有大致相同的结果尺 为什么要分割纹理 指示材料的特性 重要的外观提示，尤其是单股对象之间的相撞相似时 用于区分形状，边界和纹理 参考资料 https://baike.baidu.com/item/%E7%99%BD%E5%B9%B3%E8%A1%A1/99898 https://baike.baidu.com/item/%E9%BB%91%E4%BD%93/5398327","link":"/2022/11/25/2022-11-25-17/"},{"title":"空间分辨率和视场角及其计算方式","text":"弧度和角度的关系 弧度是角的度量单位，单位缩写是rad。定义：弧长等于半径的弧，其所对的圆心角为1弧度。 根据定义可以知角度和弧度之间的关系。一周的弧度数为2πr/r = 2π，即弧度和角度关系是 2π rad= 360º 1 rad = 360º/2π = 57.3º 1º = 2π/360º = 0.01745 rad = 17.45 mrad 空间分辨率及视场角的计算方法 空间分辨率 红外热成像仪能够识别的两个相邻目标的最小距离。通常用瞬时视场角（IFOV）大小来表示热成像仪的最小角分辨单元，单位mrad（毫弧度）。 视场角 称为总视场角或扫描视场角，表热成像仪位置固定时，所能观察到的最大空间交付范围。如图： 空间分辨率计算 m是空间分辨率（mrad），l是像间距（μm），f是镜头焦距（mm） 视场角算法 水平视场角 ，像间距l，镜头焦距f，水平像素数，17.45mrad对应1°∠ 垂直视场角 ，像间距l，镜头焦距f，垂直像素数，17.45mrad对应1°∠ 探测等级 业界根据约翰逊准则将目标探测分成探测（发现）、 识别和辨认三个等级： 探测：在时场内发现一个目标，目标所成的像在临界尺寸方向上必须占到1.5像素以上； 识别：可将目标分类，即可识别出目标是坦克、卡车或者人等，这时目标所成像在临界尺寸方向上必须占到6个像素以上 辨认：可区分开目标的型号及其他特征，这时目标缩成的像在临界尺寸方向上必须占到12个像素以上。 以上是概率目标在50%以上，背景对比度为1的情况下得到的数据。如果需要更高的探测率则需要提高成像目标占据的像素数（此时需要提升红外摄像机的硬件，例如增加镜头焦距、 减少像间距、增加分辨率等手段）。 参考资料 弧度：https://baike.baidu.com/item/%E5%BC%A7%E5%BA%A6/1533188","link":"/2022/11/29/2022-11-29-22/"},{"title":"Hexo Quick Start","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Mathjax Local Image Create a new post 1$ hexo new \"My New Post\" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","link":"/2022/11/25/hello-world/"},{"title":"Hexo+Github优化小结","text":"本文主要是对Hexo+Github部署个人Blog遇到小问题的一个汇总，涉及到主题，Pages服务及网站加速。 主题选择目前比较流行的next主题和icarus主题，这两个主题都具备一定的定制性和插件。个人更喜欢icarus主题，以下以icarus主题为例进行说明。 安装主题执行如下命令可以安装icarus主题 1npm install -S hexo-theme-icarus hexo-renderer-inferno 主题配置1hexo config theme icarus 上述命令可以生产配置文件_config.icarus.yml文件及样例配置文件。此时就可以按照http://ppoffice.github.io/hexo-theme-icarus/自定义主题，对不需要样式或者插件可以在配置文件中直接注释；可以参考样例配置文件_config.icarus.yml.example进行配置。 Pages服务选择当前可以选择Pages服务主要有github，gitee以及coding。 github访问较慢，配置简单方便，部署后可自动更新，网上可以查询到很多hexo+github的配置知道，这里就不再赘述了 gitee访问快，可定义从github同步pages库，每次更新均需要需要手动部署且会出莫名其妙的审查问题 coding被腾讯云收购以后只提供静态网站部署，但是资料写的稀烂，完全不知道怎么操作 新手还是推荐使用github pags服务，未来流量增加以后可以考虑同步到coding/gitee上 网站加速从浏览器开发人员工具上可以看到部署在github上加载最慢元素主要是图片**、js、css、字体。根据上述问题可以选择不同的加速方案。 针对hexo和主题本身的js\\css则只能通过更换国内Pags服务（本次暂不优化） 针对第三方插件和css可以使用内建或者自定义CDN来加速 针对图片文件则可以使用国内图床进行加速 使用内建或者自定义CDN进行css和js加速 next配置加速 1234567891011121314vendors:# The CDN provider of NexT internal scripts.# Available values: local | jsdelivr | unpkg | cdnjs | custom# Warning: If you are using the latest master branch of NexT, please set `internal: local`internal: local# The default CDN provider of third-party plugins.# Available values: local | jsdelivr | unpkg | cdnjs | custom# Dependencies for `plugins: local`: https://github.com/next-theme/pluginsplugins: custom# Custom CDN URL# For example:# custom_cdn_url: https://cdn.jsdelivr.net/npm/${npm_name}@${version}/${minified}# custom_cdn_url: https://cdnjs.cloudflare.com/ajax/libs/${cdnjs_name}/${version}/${cdnjs_file}custom_cdn_url: https://lib.baomitu.com/${cdnjs_name}/${version}/${cdnjs_file} 详细配置可参考https://theme-next.js.org/docs/advanced-settings/vendors，国内建议配置baomitu。 icarus配置加速 123456789# CDN provider settings# https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/speed-up-your-site-with-custom-cdn/providers: # Name or URL template of the JavaScript and/or stylesheet CDN provider cdn: loli # Name or URL template of the webfont CDN provider fontcdn: loli # Name or URL of the fontawesome icon font CDN provider iconcdn: loli 详细配置可参考https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/speed-up-your-site-with-custom-cdn/，国内建议配置loli。 使用图床进行图片下载加速当前只试用了一个图床https://imgloc.com/，只需要将主题/博客中使用到图片上传到图床，图床会生成一个或者多个外网链接（大图片图床会给出缩略图、中等规模图和原始图的链接），可以将图床外网链接直接配置在hexo主题或者博客中。本次我只是将profile图片和logo图片上传到图片。后续新写的博客则可以直接使用图床的图片链接。 其他加速措施 关闭不必要第三方插件，例如评论系统、分析系统（因为这些插件通常都会被浏览器隐私保护、去广告插件主动拦截，实际效果可自行评估） 打开博客的read more开关（在博客文件中增加&lt;!--more--&gt;），主页只显示博客的关键文字信息，不显示公式、图片等需要额外加载资源的内容 参考资料http://ppoffice.github.io/hexo-theme-icarus/","link":"/2022/12/03/2022-12-03-08/"},{"title":"纵横大数据主要观点（四）","text":"经典DBMS的挑战 数据量与处理压力带来的扩展性的挑战,主要体现在： 企业的核心业务系统，应付用户并发量与数据量增长的压力越来越严重； 企业的业务分析系统应付数据处理强度与数据量增长的压力也越来越严重。 对多种数据类型管理以及弱模式管理需求满足。 主流关系型数据库应对现代数据管理需求的挑战的主要策略，主要分两种（基于分布式与并行技术解决方案架构）： Share Disk：从名字上可以判断，主要是扩展了数据库计算能力，但是磁盘、网络IO依旧是瓶颈；典型产品Oracle RAC，实际项目中超过4个RAC节点OLTP的集群很少，当增加第一个RAC节点时数据库性能可以显著提升性能，增加更多节点数据库性能则不能线性增加，甚至可能出现多节点的数据库性能还不如单机性能（数据库主要性能瓶颈时磁盘IO瓶颈，在OLTP和OLAP都有可能发生，OLAP场景更多一些；节点数量增加并没有解决硬盘IO瓶颈，且增加节点导致的协调、控制等损耗更大）。 Share Nothing ：通过分片技术让每个节点上存储的数据都不相同，这样即可解决水平扩展中磁盘IO问题，典型产品TeraData，GreenPlum；这种架构下由于数据分散在不同节点，这种架构天然就不适合OLTP的场景（例如：表关联操作不得不进行节点间数据迁移工作）。Share Nothing架构基本上都用于OLAP场景。 数据库的改进 技术改进 列存储：数据按列存储，对于少量的查询操作则可以只读出需要列的数据而不是整表数据，数据库主要瓶颈磁盘IO/网络IO，减少读取的数据则可以提升效率； 智能扫描：主要是在存储节点提供计算能力，在存储节点上根据SQL语句过滤不必要的数据，例如传统数据库技术中对于一个没有索引的表执行select c_1,c_2 from t where r1=4需要将整个表读取到内存再根据SQL规则计算，而有智能扫描能力数据库则可以在存储节点上加入了CPU操作，过滤那些不必要的数据，减少了计算节点和存储节点之间的数据传输； 高速缓存与内存：一是通过高速缓存（Flash Cache）批量写数据减少磁盘IO操作，二是把内存当硬盘，硬盘当磁带使用，将所有数据装载到内存，定期更新内存数据到硬盘； 数据压缩：对同一列数据进行压缩，压缩以后传输到内存的数据变少，减少IO操作 数据库一体机 典型的产品包括：TeraData一体机（OLAP），Oracle Exadata一体机（OLTP和OLAP混合负载，实际更优于OLAP），Oracle Exadata一体机计算节点采用了RAC的计算架构，存储上采用InfiniBand网络。","link":"/2023/01/20/2023-01-20-22/"},{"title":"关系型数据库和MapReduce的差异","text":"关系型数据库和MapReduce的差异 OLAP关系型数据库SQL语义对表达复杂BI报表与分析要方便很多，开发人员使用MapReduce来模拟表达同样的效果SQL语义往往比较复杂； 关系型数据库的执行引擎，对SQL的执行有很多优化机制，例如执行路径优化、关联算法等，对于BI的处理和分析比较方便，而采用MapReduce则需要大量的开发工作，以及较强编程技能； 很多在SQL体系不适合实现数据处理需求（如：预测、高级聚类算法），在MapReduce中则比较容易实现； MapReduce扩展性比OLAP关系型数据库扩展性强，更适合大规模数据处理分析与工作； 在数据处理结果展示方面，很对BI工具都是基于关系型数据库，即使采用MapReduce实现数据处理分析工作，最终还是会导入到数据库中做展示。 为什么还需要MapReduce 更大的数据处理规模却需要更低的成本； 不适合关系模型的数据类型； 不适合SQL体系的处理逻辑（如：模糊聚类、孤立点分析、关联分析等）。 简而言之 关系型数据库设计的目标是，只需要你告诉他“需要什么”就行，MapReduce则需要用户告诉他具体“怎么做”，他就会帮助你在MPP环境中执行“怎么做”的过程，因此MapReduce比关系型数据库灵活很多，无论什么数据类型都是根据你要求处理。","link":"/2023/01/20/2023-01-20-23/"},{"title":"在linxu上搭建miniconda和pyspark环境","text":"下载安装miniconda 下载miniconda从清华大学镜像站中下载miniconda，下载地址https://mirrors.bfsu.edu.cn/anaconda/miniconda/，下载Miniconda3-latest-Linux-x86_64.sh 安装miniconda执行bash Miniconda3-latest-Linux-x86_64.sh 按照指引完成安装。安装时可以完成一次conda初始化，初始化脚本会在用户.bashrc中增加初始化操作。安装成功以后需要重新打开一次console，即可进入conda默认环境中。使用conda list可以查询默认环境中已经安装的包。 修改miniconda默认源在用户目录（如：/home/xxxuser/）下面新建一个.condarc，添加如下内容，即可修改miniconda默认源为清华大学镜像源 12345678910111213141516channels: - defaultsshow_channel_urls: truedefault_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud 运行conda clean -i清除索引缓存，保证用的是镜像站提供的索引。 参考资料 请参考https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/ 安装pyspark 安装方式conda环境中可以使用pip和conda安装包。conda安装pyspark是由社区维护到，具体命令可以参考conda install -h命令说明。下文使用spark推荐到pip方式安装。 1pip instal pyspark 此外，还可以通过PYSPARK_HADOOP_VERSION指定Hadoop版本。 1PYSPARK_HADOOP_VERSION=2 pip instal pyspark 其中 PYSPARK_HADOOP_VERSION值可以是： without: Spark pre-built with user-provided Apache Hadoop 2: Spark pre-built for Apache Hadoop 2.7 3: Spark pre-built for Apache Hadoop 3.3 and later (default) 参考资料 https://spark.apache.org/docs/latest/api/python/getting_started/install.html 验证安装是否成功通过如下代码验证是否安装成功 1from pyspark.sql import SparkSession pyspark以来JDK，如果没有安装JDK需要先安装JDK。在debian环境下可以执行如下命令查找安装支持JDK 12apt-cache search openjdksudo apt install openjdk-17-jdk","link":"/2023/01/26/2023-01-26-12/"},{"title":"数据治理到通用概念","text":"数据集成 数据集成集群 集群管理，新建一个数据集成的集群，通常是是一个ETL工具（数据加载的工具集合）。 数据链接 是用数据集成集群集成数据是是需要建立源数据和目标数据之间的链接。新建连接（源数据链接和和目标数据链接）； 新建作业 选在源和目标数据链接以及、数据库和表名称以及字段映射关系以及数据集成任务的执行参数 启动任务执行 业务调研 主要是完成信息架构、主题设计和流程设计。 1. 信息架构主要是数据资产的总揽。一般是在后续设计完成之后就逐步行程了信息架构。 2. 主题设计主要就是基于业务调研结果完成主题域分组、主题域以及业务对象的设计。 3. 流程设计主要是梳理清楚流程组、流程以及流程活动。这个目的是啥？？？ 标准设计 基本概念 码表：也称lookup表、数据字典，一般由中英文名称编码组成，由可枚举数据构成，存储枚举数据名称与编码的映射关系。码表的主要作用有： 数据清洗中用于标准化业务数据、补充映射字段； 质量监控中用于监控业务时间的值域范围； 纬度建模中可引申为枚举纬度。 数据标准 定义数据含义和业务规则。一般会提供名称、目录、标准编码、数据类型、长度、引用的码表、质量规则（例如是否为空、字段唯一值、重复值等）等 码表管理 定义和管理码表 模型设计 关系建模 逻辑模型（表示物理实体之间逻辑关系） 物理模型：逻辑模型物化之后就形成了物理模型，物化过程就是将逻辑模型落地到物理数据管理系统（Hive/DWS/ClickHouse）。 纬度建模 纬度：用于关阀和分析业务数据的视角，制成对数据汇总、钻取、切片分析，用于SQL 中分组（GROUP BY条件）、查询约束条件（SQL WHERE条件）、报表标签等。纬度多数具有层级结构，如：地理纬度（国家、地区、省市级别的内容）地区、时间纬度（年度、季度、月度等） 纬度表：业务分析需要用到的纬度，需要为每一个纬度建立一个纬度表，纬度表是纬度物化的结果； 事实表：归属于某个业务过程的事实逻辑表，是业务过程中对应事物的详细信息，创建逻辑事实表明即完成对公共事务明细数据沉淀，便于提前业务事务相关的明细数据；事实表数据可能来源多个源表；一起数据应用和分析都是围绕事实表来展开的； 汇总表：根据纬度表和事实表生成的汇总表，汇总表直接用于数据服务； 指标设计 业务指标 衡量目标总体特征的统计数值，是能表征企业某一个业务活动业务状况的数据指示器。业务指标用于指导技术指标，技术指标是业务指标的具体实现。一般由指标名称和指标数值（含计算公式）两部分组成。 技术指标 技术指标可分成四类： 原子指标：直接来源于事实表； 衍生指标：无来源表，由原子指标组合而成； 复合指标：由衍生指标叠加计算生成，其中的纬度、限定均继承自衍生指标。 数据集市 汇总逻辑表 由一个特定的分析对象（如会员）及其相关的统计指标组成。组成一个汇总表的统计指标都又有相同的统计粒度（如会员），汇总逻辑表面向用户提供了统计粒度（如会员）为主题的所有统计数据（如会员主题集市），汇总表直接对外提供数据服务（API）","link":"/2023/02/02/2023-02-02-21/"}],"tags":[{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"读书笔记","slug":"读书笔记","link":"/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"非暴力沟通","slug":"非暴力沟通","link":"/tags/%E9%9D%9E%E6%9A%B4%E5%8A%9B%E6%B2%9F%E9%80%9A/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"},{"name":"WSL","slug":"WSL","link":"/tags/WSL/"},{"name":"微服务","slug":"微服务","link":"/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"机器视觉","slug":"机器视觉","link":"/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"},{"name":"云计算","slug":"云计算","link":"/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"BigData","slug":"BigData","link":"/tags/BigData/"},{"name":"打数据","slug":"打数据","link":"/tags/%E6%89%93%E6%95%B0%E6%8D%AE/"}],"categories":[],"pages":[{"title":"about","text":"","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}]}